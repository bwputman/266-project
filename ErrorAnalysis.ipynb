{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import os.path\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inter-model comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df of merged predictions from each model (functional approach, only one df ever exists in memory)\n",
    "model_predictions = pd.read_csv('data/test_1.csv').merge(pd.read_csv('data/test_2.csv'), how = 'outer')\n",
    "\n",
    "\n",
    "# This block is for dev purposes until submission files are pushed to the repo\n",
    "# model_predictions = model_predictions.merge(\n",
    "#                         pd.read_csv('data/sample_submission.csv').rename(columns = {'is_duplicate' : 'cnn_duplicate'}),\n",
    "#                         on = 'test_id', \n",
    "#                         how = 'outer').merge(\n",
    "#                         pd.read_csv('data/sample_submission.csv').rename(columns = {'is_duplicate' : 'lstm_duplicate'}),\n",
    "#                         on = 'test_id', \n",
    "#                         how = 'outer').merge(\n",
    "#                         pd.read_csv('data/sample_submission.csv').rename(columns = {'is_duplicate' : 'xgb_duplicate'}),\n",
    "#                         on = 'test_id', \n",
    "#                         how = 'outer')\n",
    "\n",
    "\n",
    "# CNN\n",
    "if os.path.isfile('data/cnn_submission.csv'):\n",
    "    model_predictions = model_predictions.merge(\n",
    "                        pd.read_csv('data/cnn_submission.csv').rename(columns = {'is_duplicate' : 'cnn_duplicate'}),\n",
    "                        on = 'test_id', \n",
    "                        how = 'outer')\n",
    "\n",
    "# LSTM \n",
    "if os.path.isfile('data/lstm_submission.csv'):\n",
    "    model_predictions = model_predictions.merge(\n",
    "                    pd.read_csv('data/lstm_submission.csv').rename(columns = {'is_duplicate' : 'lstm_duplicate'}),\n",
    "                    on = 'test_id', \n",
    "                    how = 'outer')\n",
    "\n",
    "# XGBoost\n",
    "if os.path.isfile('data/xgb_submission.csv'):\n",
    "    model_predictions = model_predictions.merge(\n",
    "                    pd.read_csv('data/xgb_submission.csv').rename(columns = {'is_duplicate' : 'xgb_duplicate'}),\n",
    "                    on = 'test_id', \n",
    "                    how = 'outer')\n",
    "\n",
    "\n",
    "# Sanity Check\n",
    "col_names = list(model_predictions)\n",
    "num_rows = len(model_predictions)\n",
    "print \"Column Names:\\t\\t\" + str(col_names)\n",
    "print \"Number of Rows:\\t\\t\" + str(num_rows) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model similarity\n",
    "cnn_lstm = model_predictions['cnn_duplicate'] == model_predictions['lstm_duplicate']\n",
    "cnn_xgb = model_predictions['cnn_duplicate'] == model_predictions['xgb_duplicate']\n",
    "lstm_xgb = model_predictions['lstm_duplicate'] == model_predictions['xgb_duplicate']\n",
    "cnn_lstm_xgb = cnn_lstm & cnn_xgb\n",
    "\n",
    "print \"CNN/LSTM Similarity:\\t\\t%f\" % (len(model_predictions[cnn_lstm]) / num_rows)\n",
    "\n",
    "print \"CNN/XGB Similarity:\\t\\t%f\" % (len(model_predictions[cnn_xgb]) / num_rows)\n",
    "\n",
    "print \"LSTM/XGB Similarity:\\t\\t%f\" % (len(model_predictions[lstm_xgb]) / num_rows)\n",
    "\n",
    "print \"CNN/LSTM/XGB Similarity:\\t%f\" % (len(model_predictions[cnn_lstm_xgb]) / num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore CNN/LSTM differences\n",
    "# Print ~20 rows (small, but representative sample) and compare/contrast\n",
    "condition_1 =  (model_predictions['cnn_duplicate'] == 1) & (model_predictions['lstm_duplicate'] == 0)\n",
    "condition_2 =  (model_predictions['cnn_duplicate'] == 0) & (model_predictions['lstm_duplicate'] == 1)\n",
    "\n",
    "print \"Pairs that CNN marked as duplicates and LSTM did not.\\n\"\n",
    "for key in np.random.choice(model_predictions[condition_1]['test_id'], size = 10, replace = False):\n",
    "    print \"Q1: \" + str(model_predictions['question1'][key])\n",
    "    print \"Q2: \" + str(model_predictions['question2'][key]) + \"\\n\"\n",
    "\n",
    "print \"\".join(['=' for i in range(115)])\n",
    "print \"\\nPairs that LSTM marked as duplicates and CNN did not.\\n\"\n",
    "for key in np.random.choice(model_predictions[condition_2]['test_id'], size = 10, replace = False):\n",
    "    print \"Q1: \" + str(model_predictions['question1'][key])\n",
    "    print \"Q2: \" + str(model_predictions['question2'][key]) + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Explore CNN/XGB differences\n",
    "# Print ~20 rows (small, but representative sample) and compare/contrast\n",
    "condition_1 =  (model_predictions['cnn_duplicate'] == 1) & (model_predictions['xgb_duplicate'] == 0)\n",
    "condition_2 =  (model_predictions['cnn_duplicate'] == 0) & (model_predictions['xgb_duplicate'] == 1)\n",
    "\n",
    "print \"Pairs that CNN marked as duplicates and XGBoost did not.\\n\"\n",
    "for key in np.random.choice(model_predictions[condition_1]['test_id'], size = 10, replace = False):\n",
    "    print \"Q1: \" + str(model_predictions['question1'][key])\n",
    "    print \"Q2: \" + str(model_predictions['question2'][key]) + \"\\n\"\n",
    "\n",
    "print \"\".join(['=' for i in range(115)])\n",
    "print \"\\nPairs that XGBoost marked as duplicates and CNN did not.\\n\"\n",
    "for key in np.random.choice(model_predictions[condition_2]['test_id'], size = 10, replace = False):\n",
    "    print \"Q1: \" + str(model_predictions['question1'][key])\n",
    "    print \"Q2: \" + str(model_predictions['question2'][key]) + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore LSTM/XGB differences\n",
    "# Print ~20 rows (small, but representative sample) and compare/contrast\n",
    "condition_1 =  (model_predictions['lstm_duplicate'] == 1) & (model_predictions['xgb_duplicate'] == 0)\n",
    "condition_2 =  (model_predictions['lstm_duplicate'] == 0) & (model_predictions['xgb_duplicate'] == 1)\n",
    "\n",
    "print \"Pairs that LSTM marked as duplicates and XGBoost did not.\\n\"\n",
    "for key in np.random.choice(model_predictions[condition_1]['test_id'], size = 10, replace = False):\n",
    "    print \"Q1: \" + str(model_predictions['question1'][key])\n",
    "    print \"Q2: \" + str(model_predictions['question2'][key]) + \"\\n\"\n",
    "\n",
    "print \"\".join(['=' for i in range(115)])\n",
    "print \"\\nPairs that XGBoost marked as duplicates and LSTM did not.\\n\"\n",
    "for key in np.random.choice(model_predictions[condition_2]['test_id'], size = 10, replace = False):\n",
    "    print \"Q1: \" + str(model_predictions['question1'][key])\n",
    "    print \"Q2: \" + str(model_predictions['question2'][key]) + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove df to conserve memory\n",
    "del model_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis For Individual Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if os.path.isfile('data/cnn_train_predictions.csv'):\n",
    "    train_predictions = pd.read_csv('data/cnn_train_predictions.csv')\n",
    "    \n",
    "# Print ~25 rows (small, but representative sample) of correct predictions and explore\n",
    "# Print ~25 rows (small, but representative sample) of incorrect predictions and explore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if os.path.isfile('data/lstm_train_predictions.csv'):\n",
    "    train_predictions = pd.read_csv('data/lstm_train_predictions.csv')\n",
    "    \n",
    "# Print ~25 rows (small, but representative sample) of correct predictions and explore\n",
    "# Print ~25 rows (small, but representative sample) of incorrect predictions and explore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if os.path.isfile('data/xgb_train_predictions.csv'):\n",
    "    train_predictions = pd.read_csv('data/xgb_train_predictions.csv')\n",
    "    \n",
    "# Print ~25 rows (small, but representative sample) of correct predictions and explore\n",
    "# Print ~25 rows (small, but representative sample) of incorrect predictions and explore"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
