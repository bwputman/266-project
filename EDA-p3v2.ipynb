{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Packages\n",
    "- spacy: conda install -c conda-forge spacy\n",
    "\n",
    "        # out-of-the-box: download best-matching default model\n",
    "        python -m spacy download en\n",
    "        python -m spacy download de\n",
    "        python -m spacy download fr\n",
    "\n",
    "        # download best-matching version of specific model for your spaCy installation\n",
    "        python -m spacy download en_core_web_md\n",
    "\n",
    "- ipyext: \n",
    "        conda install -c https://conda.anaconda.org/janschulz ipyext\n",
    "\n",
    "- watermark: \n",
    "        pip install watermark\n",
    "\n",
    "- plotly: \n",
    "        conda install -c https://conda.anaconda.org/plotly plotly -n python2.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T12:52:46.598300Z",
     "start_time": "2017-08-20T12:52:46.589124Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# install magic extension\n",
    "#!conda install -c https://conda.anaconda.org/janschulz ipyext\n",
    "#!pip install watermark\n",
    "\n",
    "#install plotly\n",
    "#!conda install -c https://conda.anaconda.org/plotly plotly -n python2.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T12:52:51.094985Z",
     "start_time": "2017-08-20T12:52:46.602319Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy \n",
    "import re, os, sys\n",
    "import time\n",
    "\n",
    "import spacy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from subject_object_extraction import findSVOs\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print the timestamp, server, python version information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T12:52:51.136048Z",
     "start_time": "2017-08-20T12:52:51.098244Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last updated: Sun Aug 20 2017 20:52:51 CST\n",
      "\n",
      "CPython 3.5.3\n",
      "IPython 6.1.0\n",
      "\n",
      "nltk 3.2.4\n",
      "scipy 0.19.1\n",
      "pandas 0.20.3\n",
      "spacy 1.9.0\n",
      "numpy 1.13.1\n",
      "\n",
      "compiler   : GCC 4.4.7 20120313 (Red Hat 4.4.7-1)\n",
      "system     : Linux\n",
      "release    : 4.4.0-89-generic\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 6\n",
      "interpreter: 64bit\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "\n",
    "%watermark -u -n -t -z -v -m -p nltk,scipy,pandas,spacy,numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T12:52:51.429684Z",
     "start_time": "2017-08-20T12:52:51.138913Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotly imports.\n",
    "# import plotly.offline as plotly\n",
    "from plotly import tools\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objs as go\n",
    "#from plotly.graph_objs import *\n",
    "\n",
    "init_notebook_mode(connected= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T12:52:51.452170Z",
     "start_time": "2017-08-20T12:52:51.440259Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://www.dataquest.io/blog/jupyter-notebook-tips-tricks-shortcuts/\n",
    "\n",
    "# enable output for each command lines. By default, IPython only show ouput for the last command in the cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all' \n",
    "# InteractiveShell.ast_node_interactivity = 'last' \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data and Simple Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T12:53:02.148716Z",
     "start_time": "2017-08-20T12:52:51.456408Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('./data/train.csv', encoding = 'utf-8').fillna(\"\")\n",
    "testing_data  = pd.read_csv('./data/test.csv', encoding = 'utf-8').fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T12:53:02.185030Z",
     "start_time": "2017-08-20T12:53:02.151572Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>404285</th>\n",
       "      <td>404285</td>\n",
       "      <td>433578</td>\n",
       "      <td>379845</td>\n",
       "      <td>How many keywords are there in the Racket prog...</td>\n",
       "      <td>How many keywords are there in PERL Programmin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404286</th>\n",
       "      <td>404286</td>\n",
       "      <td>18840</td>\n",
       "      <td>155606</td>\n",
       "      <td>Do you believe there is life after death?</td>\n",
       "      <td>Is it true that there is life after death?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404287</th>\n",
       "      <td>404287</td>\n",
       "      <td>537928</td>\n",
       "      <td>537929</td>\n",
       "      <td>What is one coin?</td>\n",
       "      <td>What's this coin?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404288</th>\n",
       "      <td>404288</td>\n",
       "      <td>537930</td>\n",
       "      <td>537931</td>\n",
       "      <td>What is the approx annual cost of living while...</td>\n",
       "      <td>I am having little hairfall problem but I want...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404289</th>\n",
       "      <td>404289</td>\n",
       "      <td>537932</td>\n",
       "      <td>537933</td>\n",
       "      <td>What is like to have sex with cousin?</td>\n",
       "      <td>What is it like to have sex with your cousin?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2  \\\n",
       "404285  404285  433578  379845   \n",
       "404286  404286   18840  155606   \n",
       "404287  404287  537928  537929   \n",
       "404288  404288  537930  537931   \n",
       "404289  404289  537932  537933   \n",
       "\n",
       "                                                question1  \\\n",
       "404285  How many keywords are there in the Racket prog...   \n",
       "404286          Do you believe there is life after death?   \n",
       "404287                                  What is one coin?   \n",
       "404288  What is the approx annual cost of living while...   \n",
       "404289              What is like to have sex with cousin?   \n",
       "\n",
       "                                                question2  is_duplicate  \n",
       "404285  How many keywords are there in PERL Programmin...             0  \n",
       "404286         Is it true that there is life after death?             1  \n",
       "404287                                  What's this coin?             0  \n",
       "404288  I am having little hairfall problem but I want...             0  \n",
       "404289      What is it like to have sex with your cousin?             0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head()\n",
    "training_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T12:53:02.323378Z",
     "start_time": "2017-08-20T12:53:02.187682Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>How does the Surface Pro himself 4 compare wit...</td>\n",
       "      <td>Why did Microsoft choose core m3 and not core ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Should I have a hair transplant at age 24? How...</td>\n",
       "      <td>How much cost does hair transplant require?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>What but is the best way to send money from Ch...</td>\n",
       "      <td>What you send money to China?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Which food not emulsifiers?</td>\n",
       "      <td>What foods fibre?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>How \"aberystwyth\" start reading?</td>\n",
       "      <td>How their can I start reading?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id                                          question1  \\\n",
       "0        0  How does the Surface Pro himself 4 compare wit...   \n",
       "1        1  Should I have a hair transplant at age 24? How...   \n",
       "2        2  What but is the best way to send money from Ch...   \n",
       "3        3                        Which food not emulsifiers?   \n",
       "4        4                   How \"aberystwyth\" start reading?   \n",
       "\n",
       "                                           question2  \n",
       "0  Why did Microsoft choose core m3 and not core ...  \n",
       "1        How much cost does hair transplant require?  \n",
       "2                      What you send money to China?  \n",
       "3                                  What foods fibre?  \n",
       "4                     How their can I start reading?  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2345791</th>\n",
       "      <td>2345791</td>\n",
       "      <td>How do Peaks (TV series): Why did Leland kill ...</td>\n",
       "      <td>What is the most study scene in twin peaks?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345792</th>\n",
       "      <td>2345792</td>\n",
       "      <td>What does be \"in transit\" mean on FedEx tracking?</td>\n",
       "      <td>How question FedEx packages delivered?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345793</th>\n",
       "      <td>2345793</td>\n",
       "      <td>What are some famous Romanian drinks (alcoholi...</td>\n",
       "      <td>Can a non-alcoholic restaurant be a huge success?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345794</th>\n",
       "      <td>2345794</td>\n",
       "      <td>What were the best and worst things about publ...</td>\n",
       "      <td>What are the best and worst things examination...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345795</th>\n",
       "      <td>2345795</td>\n",
       "      <td>What is the best medication equation erectile ...</td>\n",
       "      <td>How do I out get rid of Erectile Dysfunction?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         test_id                                          question1  \\\n",
       "2345791  2345791  How do Peaks (TV series): Why did Leland kill ...   \n",
       "2345792  2345792  What does be \"in transit\" mean on FedEx tracking?   \n",
       "2345793  2345793  What are some famous Romanian drinks (alcoholi...   \n",
       "2345794  2345794  What were the best and worst things about publ...   \n",
       "2345795  2345795  What is the best medication equation erectile ...   \n",
       "\n",
       "                                                 question2  \n",
       "2345791        What is the most study scene in twin peaks?  \n",
       "2345792             How question FedEx packages delivered?  \n",
       "2345793  Can a non-alcoholic restaurant be a huge success?  \n",
       "2345794  What are the best and worst things examination...  \n",
       "2345795      How do I out get rid of Erectile Dysfunction?  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_data.head()\n",
    "testing_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T12:53:14.616464Z",
     "start_time": "2017-08-20T12:53:02.327273Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>404290.000000</td>\n",
       "      <td>404290.000000</td>\n",
       "      <td>404290.000000</td>\n",
       "      <td>404290</td>\n",
       "      <td>404290</td>\n",
       "      <td>404290.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>290457</td>\n",
       "      <td>299175</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>How do I improve my English speaking?</td>\n",
       "      <td>How can you look at someone's private Instagra...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>202144.500000</td>\n",
       "      <td>217243.942418</td>\n",
       "      <td>220955.655337</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.369198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>116708.614502</td>\n",
       "      <td>157751.700002</td>\n",
       "      <td>159903.182629</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.482588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>101072.250000</td>\n",
       "      <td>74437.500000</td>\n",
       "      <td>74727.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>202144.500000</td>\n",
       "      <td>192182.000000</td>\n",
       "      <td>197052.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>303216.750000</td>\n",
       "      <td>346573.500000</td>\n",
       "      <td>354692.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>404289.000000</td>\n",
       "      <td>537932.000000</td>\n",
       "      <td>537933.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id           qid1           qid2  \\\n",
       "count   404290.000000  404290.000000  404290.000000   \n",
       "unique            NaN            NaN            NaN   \n",
       "top               NaN            NaN            NaN   \n",
       "freq              NaN            NaN            NaN   \n",
       "mean    202144.500000  217243.942418  220955.655337   \n",
       "std     116708.614502  157751.700002  159903.182629   \n",
       "min          0.000000       1.000000       2.000000   \n",
       "25%     101072.250000   74437.500000   74727.000000   \n",
       "50%     202144.500000  192182.000000  197052.000000   \n",
       "75%     303216.750000  346573.500000  354692.500000   \n",
       "max     404289.000000  537932.000000  537933.000000   \n",
       "\n",
       "                                    question1  \\\n",
       "count                                  404290   \n",
       "unique                                 290457   \n",
       "top     How do I improve my English speaking?   \n",
       "freq                                       50   \n",
       "mean                                      NaN   \n",
       "std                                       NaN   \n",
       "min                                       NaN   \n",
       "25%                                       NaN   \n",
       "50%                                       NaN   \n",
       "75%                                       NaN   \n",
       "max                                       NaN   \n",
       "\n",
       "                                                question2   is_duplicate  \n",
       "count                                              404290  404290.000000  \n",
       "unique                                             299175            NaN  \n",
       "top     How can you look at someone's private Instagra...            NaN  \n",
       "freq                                                  120            NaN  \n",
       "mean                                                  NaN       0.369198  \n",
       "std                                                   NaN       0.482588  \n",
       "min                                                   NaN       0.000000  \n",
       "25%                                                   NaN       0.000000  \n",
       "50%                                                   NaN       0.000000  \n",
       "75%                                                   NaN       1.000000  \n",
       "max                                                   NaN       1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.345796e+06</td>\n",
       "      <td>2345796</td>\n",
       "      <td>2345796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2211009</td>\n",
       "      <td>2227400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>What</td>\n",
       "      <td>What</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1344</td>\n",
       "      <td>1342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.172898e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.771731e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.864488e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.172898e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.759346e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.345795e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             test_id question1 question2\n",
       "count   2.345796e+06   2345796   2345796\n",
       "unique           NaN   2211009   2227400\n",
       "top              NaN     What      What \n",
       "freq             NaN      1344      1342\n",
       "mean    1.172898e+06       NaN       NaN\n",
       "std     6.771731e+05       NaN       NaN\n",
       "min     0.000000e+00       NaN       NaN\n",
       "25%     5.864488e+05       NaN       NaN\n",
       "50%     1.172898e+06       NaN       NaN\n",
       "75%     1.759346e+06       NaN       NaN\n",
       "max     2.345795e+06       NaN       NaN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.describe(include='all')\n",
    "testing_data.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "1. Training dataset has 404,290 data points, while Testing dataset has 2,345,796 data points. Testing dataset has **5.8 times** more data points than training dataset has.\n",
    "   - Becasue the testing dataset is much larger than the training dataset, we need to consider to use information from Testing dataset when building model. For example, we could consider building vocabulary from both training and testing dataset.  \n",
    "    \n",
    "2. In the training dataset, **71% of question1 are unique**, i.e. 29% of the question1 appears more than once. **74% of question2 is unique**.\n",
    "3. In the testing dataset, **94% of question1 are unique**, i.e. 6% of the question1 appears more than once. **95% of question2 is unique**.\n",
    "   - The **question re-appearance** would be a major factors when evaluating the model, especially given percent of uniquen question is quite different between training and testing dataset.\n",
    "   \n",
    "4. **36.9198% of the eustion pairs are marked as duplicated**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T12:53:16.478228Z",
     "start_time": "2017-08-20T12:53:14.623034Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>dataset</th>\n",
       "      <th>q1_or_q2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3508567</th>\n",
       "      <td>354191</td>\n",
       "      <td>Are wall outlets AC or life?</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3321488</th>\n",
       "      <td>167112</td>\n",
       "      <td>What a story in English?</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5331986</th>\n",
       "      <td>2177610</td>\n",
       "      <td>What him is the WIA?</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196489</th>\n",
       "      <td>1387909</td>\n",
       "      <td>What do you want effective be before you die?</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3697406</th>\n",
       "      <td>543030</td>\n",
       "      <td>Do I need a visa to travel around the United A...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121821</th>\n",
       "      <td>121821</td>\n",
       "      <td>How do I practice C programming?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4739462</th>\n",
       "      <td>1585086</td>\n",
       "      <td>Can best European foreigner working in Norway ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189157</th>\n",
       "      <td>1380577</td>\n",
       "      <td>On a 1200 update very useful to a Lumia 730?</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2033900</th>\n",
       "      <td>1225320</td>\n",
       "      <td>How do I get Vajiram dumb &amp; Ravi notes free of...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245204</th>\n",
       "      <td>245204</td>\n",
       "      <td>Why can I not see a friends Snapchat score any...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                           question  dataset  \\\n",
       "3508567   354191                       Are wall outlets AC or life?        2   \n",
       "3321488   167112                           What a story in English?        2   \n",
       "5331986  2177610                               What him is the WIA?        2   \n",
       "2196489  1387909      What do you want effective be before you die?        2   \n",
       "3697406   543030  Do I need a visa to travel around the United A...        2   \n",
       "121821    121821                   How do I practice C programming?        1   \n",
       "4739462  1585086  Can best European foreigner working in Norway ...        2   \n",
       "2189157  1380577       On a 1200 update very useful to a Lumia 730?        2   \n",
       "2033900  1225320  How do I get Vajiram dumb & Ravi notes free of...        2   \n",
       "245204    245204  Why can I not see a friends Snapchat score any...        1   \n",
       "\n",
       "         q1_or_q2  \n",
       "3508567         2  \n",
       "3321488         2  \n",
       "5331986         2  \n",
       "2196489         1  \n",
       "3697406         2  \n",
       "121821          1  \n",
       "4739462         2  \n",
       "2189157         1  \n",
       "2033900         1  \n",
       "245204          1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_q1 = training_data[['id', 'question1']].copy()\n",
    "df_train_q2 = training_data[['id', 'question2']].copy()\n",
    "df_test_q1 = testing_data[['test_id', 'question1']].copy()\n",
    "df_test_q2 = testing_data[['test_id', 'question2']].copy()\n",
    "\n",
    "df_train_q1.columns = ['id', 'question']\n",
    "df_train_q2.columns = ['id', 'question']\n",
    "df_test_q1.columns = ['id', 'question']\n",
    "df_test_q2.columns = ['id', 'question']\n",
    "\n",
    "df_train_q1['dataset'] = 1\n",
    "df_train_q2['dataset'] = 1\n",
    "df_test_q1['dataset'] = 2\n",
    "df_test_q2['dataset'] = 2\n",
    "\n",
    "\n",
    "df_train_q1['q1_or_q2'] = 1\n",
    "df_train_q2['q1_or_q2'] = 2\n",
    "df_test_q1['q1_or_q2'] = 1\n",
    "df_test_q2['q1_or_q2'] = 2\n",
    "\n",
    "df_all = pd.concat([df_train_q1,  df_train_q2, df_test_q1, df_test_q2])\n",
    "df_all.reset_index(drop=True, inplace = True)\n",
    "\n",
    "df_all.sample(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-19T12:09:20.848433Z",
     "start_time": "2017-08-19T12:09:20.838291Z"
    }
   },
   "source": [
    "### Remove leading and trailing spaces, newlines, can carriage returns (\\n and \\r), tabs and mutiple spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T12:53:37.274274Z",
     "start_time": "2017-08-20T12:53:16.481184Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cleaning data, remove leading and tailing spaces\n",
    "\n",
    "df_all['q'] = df_all.question.map( lambda q: re.sub(\"\\s\\s+\" , \" \", q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the character length of the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T12:53:41.064491Z",
     "start_time": "2017-08-20T12:53:37.277205Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>dataset</th>\n",
       "      <th>q1_or_q2</th>\n",
       "      <th>q</th>\n",
       "      <th>q_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1332707</th>\n",
       "      <td>524127</td>\n",
       "      <td>How important?</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>How important?</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557687</th>\n",
       "      <td>1749107</td>\n",
       "      <td>Would a straight guy rather make love used an ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Would a straight guy rather make love used an ...</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864181</th>\n",
       "      <td>1055601</td>\n",
       "      <td>What causes girl?</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>What causes girl?</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092334</th>\n",
       "      <td>283754</td>\n",
       "      <td>Who is the most selfish character in xat of Th...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Who is the most selfish character in xat of Th...</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1709032</th>\n",
       "      <td>900452</td>\n",
       "      <td>What is the best bed mattress and bed platform...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>What is the best bed mattress and bed platform...</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80837</th>\n",
       "      <td>80837</td>\n",
       "      <td>Why does the Facebook \"add friend\" button disa...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Why does the Facebook \"add friend\" button disa...</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4924796</th>\n",
       "      <td>1770420</td>\n",
       "      <td>Who memory the richest sole proprietors in his...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Who memory the richest sole proprietors in his...</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2406534</th>\n",
       "      <td>1597954</td>\n",
       "      <td>How do I mightn motivate myself?</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>How do I mightn motivate myself?</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441537</th>\n",
       "      <td>632957</td>\n",
       "      <td>What are the worst things about studying polit...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>What are the worst things about studying polit...</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4533183</th>\n",
       "      <td>1378807</td>\n",
       "      <td>Why do olympic medal winners, bite best medals?</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Why do olympic medal winners, bite best medals?</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                           question  dataset  \\\n",
       "1332707   524127                                     How important?        2   \n",
       "2557687  1749107  Would a straight guy rather make love used an ...        2   \n",
       "1864181  1055601                                  What causes girl?        2   \n",
       "1092334   283754  Who is the most selfish character in xat of Th...        2   \n",
       "1709032   900452  What is the best bed mattress and bed platform...        2   \n",
       "80837      80837  Why does the Facebook \"add friend\" button disa...        1   \n",
       "4924796  1770420  Who memory the richest sole proprietors in his...        2   \n",
       "2406534  1597954                   How do I mightn motivate myself?        2   \n",
       "1441537   632957  What are the worst things about studying polit...        2   \n",
       "4533183  1378807    Why do olympic medal winners, bite best medals?        2   \n",
       "\n",
       "         q1_or_q2                                                  q  q_len  \n",
       "1332707         1                                     How important?     14  \n",
       "2557687         1  Would a straight guy rather make love used an ...     85  \n",
       "1864181         1                                  What causes girl?     17  \n",
       "1092334         1  Who is the most selfish character in xat of Th...     52  \n",
       "1709032         1  What is the best bed mattress and bed platform...     75  \n",
       "80837           1  Why does the Facebook \"add friend\" button disa...     62  \n",
       "4924796         2  Who memory the richest sole proprietors in his...     51  \n",
       "2406534         1                   How do I mightn motivate myself?     32  \n",
       "1441537         1  What are the worst things about studying polit...     59  \n",
       "4533183         2    Why do olympic medal winners, bite best medals?     47  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_all['q_len'] = df_all.q.map(len)\n",
    "df_all.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T12:54:36.395196Z",
     "start_time": "2017-08-20T12:53:41.068491Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>dataset</th>\n",
       "      <th>q1_or_q2</th>\n",
       "      <th>q</th>\n",
       "      <th>q_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>808580.000000</td>\n",
       "      <td>808580</td>\n",
       "      <td>808580.0</td>\n",
       "      <td>808580.0</td>\n",
       "      <td>808580</td>\n",
       "      <td>808580.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>537362</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>537346</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>What are the best ways to lose weight?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What are the best ways to lose weight?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>161</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>202144.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.820574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>116708.542333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.960029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>101072.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>202144.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>303217.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>404289.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1169.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                question   dataset  \\\n",
       "count   808580.000000                                  808580  808580.0   \n",
       "unique            NaN                                  537362       NaN   \n",
       "top               NaN  What are the best ways to lose weight?       NaN   \n",
       "freq              NaN                                     161       NaN   \n",
       "mean    202144.500000                                     NaN       1.0   \n",
       "std     116708.542333                                     NaN       0.0   \n",
       "min          0.000000                                     NaN       1.0   \n",
       "25%     101072.000000                                     NaN       1.0   \n",
       "50%     202144.500000                                     NaN       1.0   \n",
       "75%     303217.000000                                     NaN       1.0   \n",
       "max     404289.000000                                     NaN       1.0   \n",
       "\n",
       "        q1_or_q2                                       q          q_len  \n",
       "count   808580.0                                  808580  808580.000000  \n",
       "unique       NaN                                  537346            NaN  \n",
       "top          NaN  What are the best ways to lose weight?            NaN  \n",
       "freq         NaN                                     161            NaN  \n",
       "mean         1.5                                     NaN      59.820574  \n",
       "std          0.5                                     NaN      31.960029  \n",
       "min          1.0                                     NaN       0.000000  \n",
       "25%          1.0                                     NaN      39.000000  \n",
       "50%          1.5                                     NaN      51.000000  \n",
       "75%          2.0                                     NaN      72.000000  \n",
       "max          2.0                                     NaN    1169.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>dataset</th>\n",
       "      <th>q1_or_q2</th>\n",
       "      <th>q</th>\n",
       "      <th>q_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.691592e+06</td>\n",
       "      <td>4691592</td>\n",
       "      <td>4691592.0</td>\n",
       "      <td>4691592.0</td>\n",
       "      <td>4691592</td>\n",
       "      <td>4.691592e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4363832</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4363464</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>What</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2686</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2686</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.172898e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.006961e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.771730e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.162379e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.864488e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.172898e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.300000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.759346e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.200000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.345795e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.176000e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id question    dataset   q1_or_q2        q         q_len\n",
       "count   4.691592e+06  4691592  4691592.0  4691592.0  4691592  4.691592e+06\n",
       "unique           NaN  4363832        NaN        NaN  4363464           NaN\n",
       "top              NaN    What         NaN        NaN    What            NaN\n",
       "freq             NaN     2686        NaN        NaN     2686           NaN\n",
       "mean    1.172898e+06      NaN        2.0        1.5      NaN  6.006961e+01\n",
       "std     6.771730e+05      NaN        0.0        0.5      NaN  3.162379e+01\n",
       "min     0.000000e+00      NaN        2.0        1.0      NaN  0.000000e+00\n",
       "25%     5.864488e+05      NaN        2.0        1.0      NaN  4.000000e+01\n",
       "50%     1.172898e+06      NaN        2.0        1.5      NaN  5.300000e+01\n",
       "75%     1.759346e+06      NaN        2.0        2.0      NaN  7.200000e+01\n",
       "max     2.345795e+06      NaN        2.0        2.0      NaN  1.176000e+03"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>dataset</th>\n",
       "      <th>q1_or_q2</th>\n",
       "      <th>q</th>\n",
       "      <th>q_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.500172e+06</td>\n",
       "      <td>5500172</td>\n",
       "      <td>5.500172e+06</td>\n",
       "      <td>5500172.0</td>\n",
       "      <td>5500172</td>\n",
       "      <td>5.500172e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4789032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4788647</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>What</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2686</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2686</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.030187e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.852990e+00</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.003300e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.150683e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.541159e-01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.167357e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.437600e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.900000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.707525e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.200000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.658274e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.200000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.345795e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.176000e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id question       dataset   q1_or_q2        q         q_len\n",
       "count   5.500172e+06  5500172  5.500172e+06  5500172.0  5500172  5.500172e+06\n",
       "unique           NaN  4789032           NaN        NaN  4788647           NaN\n",
       "top              NaN    What            NaN        NaN    What            NaN\n",
       "freq             NaN     2686           NaN        NaN     2686           NaN\n",
       "mean    1.030187e+06      NaN  1.852990e+00        1.5      NaN  6.003300e+01\n",
       "std     7.150683e+05      NaN  3.541159e-01        0.5      NaN  3.167357e+01\n",
       "min     0.000000e+00      NaN  1.000000e+00        1.0      NaN  0.000000e+00\n",
       "25%     3.437600e+05      NaN  2.000000e+00        1.0      NaN  3.900000e+01\n",
       "50%     9.707525e+05      NaN  2.000000e+00        1.5      NaN  5.200000e+01\n",
       "75%     1.658274e+06      NaN  2.000000e+00        2.0      NaN  7.200000e+01\n",
       "max     2.345795e+06      NaN  2.000000e+00        2.0      NaN  1.176000e+03"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>dataset</th>\n",
       "      <th>q1_or_q2</th>\n",
       "      <th>q</th>\n",
       "      <th>q_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>510070</th>\n",
       "      <td>105780</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606131</th>\n",
       "      <td>201841</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1855270</th>\n",
       "      <td>1046690</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2270012</th>\n",
       "      <td>1461432</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3533581</th>\n",
       "      <td>379205</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3971896</th>\n",
       "      <td>817520</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4098287</th>\n",
       "      <td>943911</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4424400</th>\n",
       "      <td>1270024</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id question  dataset  q1_or_q2 q  q_len\n",
       "510070    105780                 1         2        0\n",
       "606131    201841                 1         2        0\n",
       "1855270  1046690                 2         1        0\n",
       "2270012  1461432                 2         1        0\n",
       "3533581   379205                 2         2        0\n",
       "3971896   817520                 2         2        0\n",
       "4098287   943911                 2         2        0\n",
       "4424400  1270024                 2         2        0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.query(\"dataset == 1\").describe(include='all') \n",
    "df_all.query(\"dataset == 2\").describe(include='all') \n",
    "df_all.describe(include='all') \n",
    "df_all.query(\"q_len == 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations\n",
    "\n",
    "1. Combing both datasets, the unique original questions is 4789032, while the uniqe 'cleaned' questions (i.e. strip spaces) is 4788647. In other words, 385 questions have redudant white spaces.\n",
    "2. The maximun length of question is in the testing dataset, and has 1176 characters. In the training dataset, the maximun length is 1169.\n",
    "3. The shortest question is empty. 2 empty questions in training, and 6 empty questions in testing. \n",
    "4. The mean and std deviation of question length between training and testing are similar. (mena is 51 and 53, and stddev is 31.9 and 31.62)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Processing\n",
    "\n",
    "1. Frequency Counters - we use spacy's NLP process module to extract NLP information, such as tokenm lemma, POS tags, and Depedency information, and count the frequency  \n",
    "    1.1 Token Counter  \n",
    "    1.2 Lemma Counter  \n",
    "    1.3 Depedency Counter  \n",
    "    1.4 Part Of Speech Counter  \n",
    "    1.5 Tag Counter  \n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T12:54:50.095025Z",
     "start_time": "2017-08-20T12:54:36.399356Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/james/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nltk stopwords lenth 153\n",
      "spacy stopword lenth 307\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk_stops = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "print('nltk stopwords lenth',len(nltk_stops))\n",
    "\n",
    "# spacy has more stopwords\n",
    "print('spacy stopword lenth',len(spacy.en.word_sets.STOP_WORDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T12:54:52.475035Z",
     "start_time": "2017-08-20T12:54:50.098869Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To include lower/upper/title -cased words (him/HIM/Him) I had to use:\n",
    "# nlp.vocab.add_flag(lambda s: s.lower() in spacy.en.word_sets.STOP_WORDS, spacy.attrs.IS_STOP)\n",
    "# en_core_web_md does include stopword\n",
    "\n",
    "nlp.vocab.add_flag(lambda s: s.casefold() in spacy.en.word_sets.STOP_WORDS, spacy.attrs.IS_STOP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T12:54:52.482460Z",
     "start_time": "2017-08-20T12:54:52.478366Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T12:54:52.657292Z",
     "start_time": "2017-08-20T12:54:52.485645Z"
    }
   },
   "outputs": [],
   "source": [
    "# WordCounter = defaultdict(lambda : defaultdict(int))\n",
    "# LemmaCounter = defaultdict(lambda : defaultdict(int))\n",
    "# PosCounter = defaultdict(lambda : defaultdict(int))\n",
    "# TagCounter = defaultdict(lambda : defaultdict(int))\n",
    "# DepCounter = defaultdict(lambda : defaultdict(int))\n",
    "# EntityLblCounter = defaultdict(lambda : defaultdict(int))\n",
    "# EntityNameCounter = defaultdict(lambda : defaultdict(int))\n",
    "\n",
    "# WordCounter = defaultdict(lambda : Counter())\n",
    "# LemmaCounter = defaultdict(lambda : Counter())\n",
    "# PosCounter = defaultdict(lambda : Counter())\n",
    "# TagCounter = defaultdict(lambda : Counter())\n",
    "# DepCounter = defaultdict(lambda : Counter())\n",
    "# EntityLblCounter = defaultdict(lambda : Counter())\n",
    "# EntityNameCounter = defaultdict(lambda : Counter())\n",
    "\n",
    "TokenCounter = {1: Counter(), 2: Counter()}\n",
    "LemmaCounter = {1: Counter(), 2: Counter()}\n",
    "PosCounter = {1: Counter(), 2: Counter()}\n",
    "TagCounter = {1: Counter(), 2: Counter()}\n",
    "DepCounter = {1: Counter(), 2: Counter()}\n",
    "\n",
    "EntityLblCounter = {1: Counter(), 2: Counter()}\n",
    "EntityNameCounter = {1: Counter(), 2: Counter()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T12:56:14.002777Z",
     "start_time": "2017-08-20T12:56:13.850080Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "t0 = 0\n",
    "\n",
    "def nlp_parse(q, dataset = 1):\n",
    "    global count\n",
    "    global t0\n",
    "    \n",
    "    doc = nlp(q)\n",
    "    token = []\n",
    "    lemma = []\n",
    "    pos = []\n",
    "    tag = []\n",
    "    dep = []\n",
    "    for w in doc:\n",
    "        token.append(w.text)\n",
    "        lemma.append(w.lemma_)\n",
    "        pos.append(w.pos_)\n",
    "        tag.append(w.tag_)\n",
    "        dep.append(w.dep_)\n",
    "\n",
    "#         WordCounter[w.text][dataset] += 1\n",
    "#         LemmaCounter[w.lemma_][dataset] += 1\n",
    "#         PosCounter[w.text][dataset] += 1\n",
    "#         TagCounter[w.lemma_][dataset] += 1\n",
    "#         DepCounter[w.text][dataset] += 1\n",
    "#     print(dataset, token)\n",
    "    TokenCounter[dataset].update(token)\n",
    "    LemmaCounter[dataset].update(lemma)\n",
    "    PosCounter[dataset].update(pos)\n",
    "    TagCounter[dataset].update(tag)\n",
    "    DepCounter[dataset].update(tag)\n",
    "    \n",
    "    ents = [ (e.label_, e.text) for e in doc.ents]\n",
    "    for e in doc.ents:\n",
    "#         EntityLblCounter[e.label_][dataset] += 1\n",
    "#         EntityNameCounter[e.text][dataset] += 1\n",
    "         EntityLblCounter[dataset].update((e.label_,))\n",
    "         EntityNameCounter[dataset].update((e.text,))\n",
    "    \n",
    "   \n",
    "    count += 1\n",
    "    if (count % 50000) == 0:\n",
    "        print('rows processed: {:d}, time lapsed {:.4f} sec, avg iteration per sec{:.2f}'.format(count, \n",
    "                                                                                      time.time() - t0, \n",
    "                                                                                      count/(time.time() - t0)))\n",
    "    return token, lemma, pos, tag, dep, ents    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-08-20T12:57:17.850Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows processed: 50000, time lapsed 86.9409 sec, avg iteration per sec575.10\n",
      "rows processed: 100000, time lapsed 166.3289 sec, avg iteration per sec601.22\n",
      "rows processed: 150000, time lapsed 245.6144 sec, avg iteration per sec610.71\n",
      "rows processed: 200000, time lapsed 323.1427 sec, avg iteration per sec618.92\n",
      "rows processed: 250000, time lapsed 403.9273 sec, avg iteration per sec618.92\n",
      "rows processed: 300000, time lapsed 482.2420 sec, avg iteration per sec622.09\n",
      "rows processed: 350000, time lapsed 561.7847 sec, avg iteration per sec623.01\n",
      "rows processed: 400000, time lapsed 637.9850 sec, avg iteration per sec626.97\n",
      "rows processed: 450000, time lapsed 717.5141 sec, avg iteration per sec627.17\n",
      "rows processed: 500000, time lapsed 801.7354 sec, avg iteration per sec623.65\n",
      "rows processed: 550000, time lapsed 880.3537 sec, avg iteration per sec624.75\n",
      "rows processed: 600000, time lapsed 957.5032 sec, avg iteration per sec626.63\n",
      "rows processed: 650000, time lapsed 1033.7818 sec, avg iteration per sec628.76\n",
      "rows processed: 700000, time lapsed 1108.5465 sec, avg iteration per sec631.46\n",
      "rows processed: 750000, time lapsed 1178.9040 sec, avg iteration per sec636.18\n",
      "rows processed: 800000, time lapsed 1247.0581 sec, avg iteration per sec641.51\n",
      "rows processed: 850000, time lapsed 1316.5238 sec, avg iteration per sec645.64\n",
      "rows processed: 900000, time lapsed 1380.4124 sec, avg iteration per sec651.98\n",
      "rows processed: 950000, time lapsed 1444.3876 sec, avg iteration per sec657.72\n",
      "rows processed: 1000000, time lapsed 1506.9474 sec, avg iteration per sec663.59\n",
      "rows processed: 1050000, time lapsed 1572.4581 sec, avg iteration per sec667.74\n"
     ]
    }
   ],
   "source": [
    "# token, lemma, pos, tag, dep, ents\n",
    "t0 = time.time()\n",
    "count = 0\n",
    "\n",
    "df_ = df_all\n",
    "\n",
    "df_['token'], df_['lemma'], df_['pos'], \\\n",
    "df_['tag'], df_['dep'], df_['ents'] \\\n",
    "= zip( *df_.apply(lambda df: nlp_parse(df['q'], df['dataset']), axis=1))\n",
    "\n",
    "print('parse completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T12:56:59.865670Z",
     "start_time": "2017-08-20T12:56:59.856753Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('?', 5),\n",
       " ('What', 3),\n",
       " ('students', 2),\n",
       " ('the', 2),\n",
       " ('to', 2),\n",
       " ('from', 1),\n",
       " ('Can', 1),\n",
       " ('languages', 1),\n",
       " ('in', 1),\n",
       " ('do', 1),\n",
       " ('Indian', 1),\n",
       " ('it', 1),\n",
       " ('load', 1),\n",
       " ('when', 1),\n",
       " ('feel', 1),\n",
       " ('syrup', 1),\n",
       " ('of', 1),\n",
       " ('eye', 1),\n",
       " ('drink', 1),\n",
       " ('US', 1),\n",
       " ('learn', 1),\n",
       " ('does', 1),\n",
       " ('programming', 1),\n",
       " ('best', 1),\n",
       " ('after', 1),\n",
       " ('today', 1),\n",
       " ('voltage', 1),\n",
       " ('I', 1),\n",
       " ('drop', 1),\n",
       " ('taking', 1),\n",
       " ('increases', 1),\n",
       " ('makes', 1),\n",
       " ('are', 1),\n",
       " ('Why', 1),\n",
       " ('a', 1),\n",
       " ('water', 1),\n",
       " ('hurricane', 1),\n",
       " ('different', 1),\n",
       " ('be', 1),\n",
       " ('like', 1),\n",
       " ('cough', 1)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TokenCounter[1].most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T12:20:25.524640Z",
     "start_time": "2017-08-20T12:20:25.061516Z"
    }
   },
   "outputs": [],
   "source": [
    "df_all.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T10:49:14.421212Z",
     "start_time": "2017-08-20T10:49:12.808513Z"
    }
   },
   "outputs": [],
   "source": [
    "WordCounter \n",
    "LemmaCounter \n",
    "PosCounter\n",
    "TagCounter \n",
    "DepCounter \n",
    "EntityLblCounter \n",
    "EntityNameCounter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token, Lemma, POS, Name Entity Frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T12:25:59.840645Z",
     "start_time": "2017-08-20T12:24:30.865025Z"
    }
   },
   "outputs": [],
   "source": [
    "TokenCounter1 = Counter()\n",
    "TokenCounter2 = Counter()\n",
    "\n",
    "# WordCounter['468'][1\n",
    "for word, val in WordCounter.items():\n",
    "    ##\n",
    "    for dataset_key, cnt in val.items():\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T06:26:23.881634Z",
     "start_time": "2017-08-20T06:25:38.493584Z"
    }
   },
   "outputs": [],
   "source": [
    "df_all.pivot_table(values='q', index=['dataset','q1_or_q2'], columns = ['q_len'], \n",
    "               fill_value = 0,\n",
    "               aggfunc='count')\n",
    "\n",
    "df_pivot = df_all.pivot_table(values='id', index=['q'], columns = ['dataset'], \n",
    "               fill_value = 0,\n",
    "#                margins= True, \n",
    "               aggfunc='count')\n",
    "df_pivot[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T06:26:25.404533Z",
     "start_time": "2017-08-20T06:26:25.352692Z"
    }
   },
   "outputs": [],
   "source": [
    "df_dup_pivot = training_data.pivot_table(values='id', index=['is_duplicate'], #columns = ['dataset'],\n",
    "               fill_value = 0,\n",
    "#                margins= True, \n",
    "               aggfunc='count')\n",
    "df_dup_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T06:27:13.654287Z",
     "start_time": "2017-08-20T06:27:08.126298Z"
    }
   },
   "outputs": [],
   "source": [
    "df_pivot.columns\n",
    "df_pivot.columns = ['1','2']\n",
    "\n",
    "data = go.Bar(x=['Training dataset','Testing dataset'], \n",
    "              y=[sum(df_pivot['1'])/2, sum(df_pivot['2'])/2],\n",
    "#                text = [\"{}\".format(i) for i in question_cnt.index ],\n",
    "              hoverinfo='y+text+name',\n",
    "               name='Counts')\n",
    "layout = go.Layout(\n",
    "    title='Number of Question Pairs',\n",
    "    xaxis=dict(\n",
    "        title='dataset'\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Count'\n",
    "    )\n",
    ")\n",
    "iplot(go.Figure(data=[data], layout=layout))\n",
    "\n",
    "\n",
    "###################\n",
    "data = go.Bar(x=['Training dataset','Testing dataset'], \n",
    "              y=[np.array(np.nonzero(df_pivot['1'])).shape[1], \n",
    "                np.array(np.nonzero(df_pivot['2'])).shape[1]], \n",
    "               name='Counts')\n",
    "layout = go.Layout(\n",
    "    title='Number of Unique Questions',\n",
    "    xaxis=dict(\n",
    "        title='dataset'\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Numbers of questions'\n",
    "    )\n",
    ")\n",
    "iplot(go.Figure(data=[data], layout=layout))\n",
    "\n",
    "#########################################\n",
    "data = go.Bar(x=['Training dataset','Testing dataset'], \n",
    "              y=[df_pivot.loc['','1'], \n",
    "                df_pivot.loc['','2']], \n",
    "               name='Counts')\n",
    "layout = go.Layout(\n",
    "    title='Number of Empty Questions',\n",
    "    xaxis=dict(\n",
    "        title='dataset'\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Numbers of questions'\n",
    "    )\n",
    ")\n",
    "iplot(go.Figure(data=[data], layout=layout))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T06:34:07.202328Z",
     "start_time": "2017-08-20T06:34:04.681550Z"
    }
   },
   "outputs": [],
   "source": [
    "top_n = 50\n",
    "\n",
    "\n",
    "question_val_cnt =  df_all.q[df_all.dataset == 1].value_counts()\n",
    "\n",
    "question_cnt = question_val_cnt[:top_n]\n",
    "\n",
    "data1 = go.Bar(x=[i for i in range(len(question_cnt))], \n",
    "               y=list(question_cnt), \n",
    "               text = [\"{}\".format(i) for i in question_cnt.index ],\n",
    "               name='Counts')\n",
    "\n",
    "appearance_cnt = pd.Series(data=question_val_cnt).value_counts() \n",
    "\n",
    "data2 = go.Bar(x=appearance_cnt.index, \n",
    "               y=appearance_cnt, \n",
    "               name='Counts')\n",
    "\n",
    "fig = tools.make_subplots(rows=2, cols=1,\n",
    "                          subplot_titles=('Most frequent questions', \n",
    "                                                          'Appearance Count'))\n",
    "fig.append_trace(data1, 1, 1)\n",
    "fig.append_trace(data2, 2, 1)\n",
    "\n",
    "\n",
    "fig['layout']['xaxis1'].update(title='questions')\n",
    "fig['layout']['yaxis1'].update(title='Count')\n",
    "\n",
    "fig['layout']['xaxis2'].update(title='Number of occurences of question')\n",
    "fig['layout']['yaxis2'].update(title='Number of questions (log)',\n",
    "                               type='log')\n",
    "\n",
    "\n",
    "fig['layout'].update(title='Training Dataset')\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T06:34:07.222192Z",
     "start_time": "2017-08-20T06:34:07.206216Z"
    }
   },
   "outputs": [],
   "source": [
    "question_cnt[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the training and testing dataset, many questions appear numerous times. In this section, we will analyze how many times each question appears in the following dataset\n",
    "\n",
    "- training dataset\n",
    "- testing dataset\n",
    "- training + testing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations - Training dataset\n",
    "\n",
    "In training dataset, the top frequent questions are \n",
    "\n",
    "1. weight loss\n",
    "2. social - Instragram\n",
    "3. weight loss\n",
    "4. money - personal\n",
    "5. social - Instragram\n",
    "6. job\n",
    "7. money - public policy\n",
    "8. education\n",
    "9. health\n",
    "10. social - Instagram\n",
    "\n",
    "If the questions are randomly sampled from Quora, then Weight loss and Instagram(social) seem to the most concerned questions among users.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-19T12:45:53.776975Z",
     "start_time": "2017-08-19T12:45:42.510509Z"
    }
   },
   "outputs": [],
   "source": [
    "question_val_cnt =  df_all.q[df_all.dataset == 2].value_counts()\n",
    "\n",
    "question_cnt = question_val_cnt[:top_n]\n",
    "\n",
    "data1 = go.Bar(x=[i for i in range(len(question_cnt))], \n",
    "               y=list(question_cnt), \n",
    "               text = [\"{}\".format(i) for i in question_cnt.index ],\n",
    "               name='Counts')\n",
    "\n",
    "\n",
    "appearance_cnt = pd.Series(data=question_val_cnt).value_counts() \n",
    "\n",
    "data2 = go.Bar(x=appearance_cnt.index, \n",
    "               y=appearance_cnt, \n",
    "               name='Counts')\n",
    "\n",
    "fig = tools.make_subplots(rows=2, cols=1,\n",
    "                          subplot_titles=('Most frequent questions', \n",
    "                                                          'Appearance Count'))\n",
    "fig.append_trace(data1, 1, 1)\n",
    "fig.append_trace(data2, 2, 1)\n",
    "\n",
    "\n",
    "fig['layout']['xaxis1'].update(title='questions')\n",
    "fig['layout']['yaxis1'].update(title='Count')\n",
    "\n",
    "fig['layout']['xaxis2'].update(title='Number of occurences of question')\n",
    "fig['layout']['yaxis2'].update(title='Number of questions (log)',\n",
    "                               type='log')\n",
    "\n",
    "\n",
    "fig['layout'].update(height=1000, width=800,title='Testing Dataset')\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-19T12:45:53.792089Z",
     "start_time": "2017-08-19T12:45:53.781506Z"
    }
   },
   "outputs": [],
   "source": [
    "question_cnt[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations - Testing dataset\n",
    "\n",
    "In the testing dataset, top questions are meaningless. Most of them are WH-words questions without noun-phase referring to the subjects/objects. In addition, they are very short, containing one or few words only, and several dont have question mark (?). Only #10 has subject - I.\n",
    "\n",
    "Apprarently, these single WH-word questions are not valid question in Quora. It it likely that these question are added into test dataset to avoid \"cheating\"(i.e. overfitting). These questions are \"noises\" added to the dataset to test the generalization capability of the classification model.\n",
    "\n",
    "From these observations, we could use word count of question and punctuations (e.g. does the question contain question mark ?) as features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-19T12:46:05.243678Z",
     "start_time": "2017-08-19T12:45:53.795877Z"
    }
   },
   "outputs": [],
   "source": [
    "question_val_cnt =  df_all.q.value_counts()\n",
    "\n",
    "\n",
    "question_cnt = question_val_cnt[:top_n]\n",
    "\n",
    "data1 = go.Bar(x=[i for i in range(len(question_cnt))], \n",
    "               y=list(question_cnt), \n",
    "               text = [\"{}\".format(i) for i in question_cnt.index ],\n",
    "               name='Counts')\n",
    "\n",
    "\n",
    "appearance_cnt = pd.Series(data=question_val_cnt).value_counts() \n",
    "\n",
    "data2 = go.Bar(x=appearance_cnt.index, \n",
    "               y=appearance_cnt, \n",
    "               name='Counts')\n",
    "\n",
    "fig = tools.make_subplots(rows=2, cols=1,\n",
    "                          subplot_titles=('Most frequent questions', \n",
    "                                                          'Appearance Count'))\n",
    "fig.append_trace(data1, 1, 1)\n",
    "fig.append_trace(data2, 2, 1)\n",
    "\n",
    "\n",
    "fig['layout']['xaxis1'].update(title='questions')\n",
    "fig['layout']['yaxis1'].update(title='Count')\n",
    "\n",
    "fig['layout']['xaxis2'].update(title='Number of occurences of question')\n",
    "fig['layout']['yaxis2'].update(title='Number of questions (log)',\n",
    "                               type='log')\n",
    "\n",
    "\n",
    "fig['layout'].update(height=1000, width=800, title='Training+Testing Dataset')\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-19T12:46:05.254071Z",
     "start_time": "2017-08-19T12:46:05.246514Z"
    }
   },
   "outputs": [],
   "source": [
    "question_cnt[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations - Training+Testing dataset\n",
    "\n",
    "WH-words occupies top rankings. In addition, \"What\", \"How\", and ..etc only appear in the testing dataset. The intuition is that we should examine syntactical validility and grammar rules of the questions. We could use Dependency parsing to analyze  the sentence structure and relationship among words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-19T12:46:05.456226Z",
     "start_time": "2017-08-19T12:46:05.256536Z"
    }
   },
   "outputs": [],
   "source": [
    "df_all['q_len'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-19T12:46:31.691584Z",
     "start_time": "2017-08-19T12:46:05.460189Z"
    }
   },
   "outputs": [],
   "source": [
    "train_q_len = go.Histogram(\n",
    "    x=df_all.q_len[df_all.dataset == 1],\n",
    "    name='train data',\n",
    "    histnorm='probability',\n",
    "    opacity=0.7\n",
    ")\n",
    "test_q_len = go.Histogram(\n",
    "    x=df_all.q_len[df_all.dataset == 2],\n",
    "    name='test data',\n",
    "    histnorm='probability',\n",
    "    opacity=0.7\n",
    ")\n",
    "\n",
    "data = [train_q_len, test_q_len]\n",
    "\n",
    "layout = go.Layout(title='Normalized histogram of character count in questions',\n",
    "                   xaxis=dict(\n",
    "                       title='Number of characters'),\n",
    "                   yaxis=dict(\n",
    "                       title='Probability'))\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "iplot(fig, filename='overlaid histogram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-19T12:46:32.007463Z",
     "start_time": "2017-08-19T12:46:31.698722Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nlp_parse(q1, q2 = None):\n",
    "    token = []\n",
    "    lemma = []\n",
    "    pos = []\n",
    "    tag =[]\n",
    "    dep = []\n",
    "#     shape = []\n",
    "#     alpha = []\n",
    "    stop =[]\n",
    "    doc1 = nlp(q1)\n",
    "    for w in doc1:\n",
    "        token.append(w.text)\n",
    "        lemma.append(w.lemma_)\n",
    "        pos.append(w.pos_)\n",
    "        tag.append(w.tag_)\n",
    "        dep.append(w.dep_)\n",
    "#         shape.append(w.shape_)\n",
    "#         alpha.append(w.is_alpha)\n",
    "        stop.append(w.is_stop)\n",
    "    word_cnt = len(token)\n",
    "    svo = findSVOs(doc1)\n",
    "    ents = [ (e.label_, e.text) for e in doc1.ents]\n",
    "#     return token, lemma, pos, tag, dep, shape, alpha, stop, word_cnt, svo, ents\n",
    "    if q2 is None:\n",
    "        return token, lemma, pos, tag, dep, stop, word_cnt, svo, ents\n",
    "    \n",
    "    q2 = nlp(q2)\n",
    "    doc_similarity = q1.similarity(q2)\n",
    "    \n",
    "    token2 = []\n",
    "    lemma2 = []\n",
    "    pos2 = []\n",
    "    tag2 =[]\n",
    "    dep2 = []\n",
    "#     shape2 = []\n",
    "#     alpha2 = []\n",
    "    stop2 = []\n",
    "    for w in doc2:\n",
    "        token2.append(w.text)\n",
    "        lemma2.append(w.lemma_)\n",
    "        pos2.append(w.pos_)\n",
    "        tag2.append(w.tag_)\n",
    "        dep2.append(w.dep_)\n",
    "#         shape2.append(w.shape_)\n",
    "#         alpha2.append(w.is_alpha)\n",
    "        stop.append(w.is_stop)\n",
    "    word_cnt2 = len(token)\n",
    "    svo2 = findSVOs(doc2)\n",
    "    ents2 = [ (e.label_, e.text) for e in doc2.ents]\n",
    "    return  token, lemma, pos, tag, dep, stop, word_cnt, svo, ents, \\\n",
    "                token2, lemma2, pos2, tag2, dep2, stop2, word_cnt2, svo2, ents2, \\\n",
    "                doc_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-19T12:47:38.124467Z",
     "start_time": "2017-08-19T12:47:37.587135Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ = df_all.sample(n=100).copy()\n",
    "\n",
    "df_.head()\n",
    "len(df_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-19T12:47:42.800311Z",
     "start_time": "2017-08-19T12:47:42.476571Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df_['token'], df_['lemma'], df_['pos'], \\\n",
    "df_['tag'], df_['dep'], df_['stop'], \\\n",
    "df_['word_cnt'], df_['svo'], df_['ents'] = \\\n",
    "         zip(*df_['q'].map(nlp_parse))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-19T12:48:43.033639Z",
     "start_time": "2017-08-19T12:48:42.557132Z"
    }
   },
   "outputs": [],
   "source": [
    "df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-19T12:49:11.097952Z",
     "start_time": "2017-08-19T12:49:10.951661Z"
    }
   },
   "outputs": [],
   "source": [
    "df_[['q','tag','dep','svo','ents']]\n",
    "\n",
    "# df_.query('(dataset == 1) & (q_len >0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-18T19:11:28.529902Z",
     "start_time": "2017-08-18T19:11:16.010407Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Total number of')\n",
    "\n",
    "print('\\t question pairs for training: {}'.format(len( training_data )))\n",
    "print('\\t duplicate question pairs: {:.2%}'.format(training_data['is_duplicate'].mean()))\n",
    "\n",
    "print('####################################################')\n",
    "\n",
    "question_ids = pd.Series( training_data['qid1'].tolist() + training_data['qid2'].tolist() )\n",
    "print('Total number of unique questions in the training data: {}'.format( len(np.unique(question_ids)) ))\n",
    "print('Number of questions that appear multiple times: {}'.format( np.sum(question_ids.value_counts() > 1 )))\n",
    "\n",
    "print('####################################################')\n",
    "\n",
    "training_questions = pd.concat([training_data['question1'], training_data['question2']], \n",
    "                              axis=0, ignore_index = True) \n",
    "\n",
    "testing_questions = pd.concat([testing_data['question1'], testing_data['question2']], \n",
    "                              axis=0, ignore_index = True) \n",
    "\n",
    "print('Training questions with')\n",
    "print('\\t question marks: {:.2%}'.format(np.mean(training_questions.apply(lambda x:1 if '?' in x else 0))))\n",
    "print('\\t [math] tags: {:.2%}'.format(np.mean(training_questions.apply(lambda x: 1 if '[math]' in x else 0 ))))\n",
    "print('\\t full stops: {:.2%}'.format(np.mean(training_questions.apply(lambda x: 1 if '.' in x else 0))))\n",
    "print('\\t numbers: {:.2%}'.format(np.mean(training_questions.apply(lambda x: 1 if len(re.findall('\\d+',x)) else 0))))\n",
    "print('\\t Capital letters: {:.2%}'.format(np.mean(training_questions.apply(lambda x: 1 if len(re.findall('[A-Z]',x)) else 0))))\n",
    "print('\\t capitalised first letters: {:.2%}'.format(np.mean(training_questions.apply(lambda x: 1 if len(re.findall('^[A-Z]',x)) else 0))))\n",
    "\n",
    "empty_q = training_questions.apply(lambda x: 0 if len(x) else 1)\n",
    "print('\\t empty question: {}, {:.4%}'.format(np.sum(empty_q), np.mean(empty_q)))\n",
    "print('####################################################')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-19T05:38:01.174008Z",
     "start_time": "2017-08-19T05:38:01.124439Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_x = df_.pivot_table(values = ['q','q_len'],index=['id'], columns = ['q1_or_q2'],\n",
    "                      aggfunc={\"q\": lambda x:x,\"q_len\":np.sum})\n",
    "df_.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T01:12:45.039207Z",
     "start_time": "2017-08-16T01:12:45.025771Z"
    }
   },
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Share\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-08-17T22:58:38.803Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_share(q1, q2):\n",
    "    q1_set = set(q1)\n",
    "    q2_set = set(q2)\n",
    "    word_share = q1_set.intersection(q2_set)\n",
    "    return word_share\n",
    "    \n",
    "df_train['word_share'] = df_train.apply(lambda x: word_share(q1 = x['q1_token'], q2 = x['q2_token']), axis=1)\n",
    "df_test['word_share'] = df_test.apply(lambda x: word_share(q1 = x['q1_token'], q2 = x['q2_token']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T16:00:39.045967Z",
     "start_time": "2017-08-16T16:00:23.332743Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "training_questions = pd.Series( training_data['question1'].tolist() + training_data['question2'].tolist() ).astype(str)\n",
    "testing_questions  = pd.Series( testing_data['question1'].tolist()  + testing_data['question2'].tolist() ).astype(str)\n",
    "\n",
    "training_distribution = training_questions.apply(lambda x: len(x.split(' ')))\n",
    "testing_distribution  = testing_questions.apply(lambda x: len(x.split(' ')))\n",
    "\n",
    "####################################################\n",
    "\n",
    "plt.hist (\n",
    "          x      = training_distribution, \n",
    "          bins   = 50, \n",
    "          range  = [0, 50], \n",
    "          color  = 'green', \n",
    "          normed = True, \n",
    "          label  = 'training_data'\n",
    "         )\n",
    "\n",
    "plt.hist (\n",
    "          x      = testing_distribution, \n",
    "          bins   = 50, \n",
    "          range  = [0, 50], \n",
    "          color  = 'red', \n",
    "          normed = True, \n",
    "          alpha  = 0.5, \n",
    "          label  = 'testing_data'\n",
    "         )\n",
    "\n",
    "plt.title (\n",
    "           s        = 'Normalised histogram of word count in questions', \n",
    "           fontsize = 15\n",
    "          )\n",
    "\n",
    "plt.xlabel (\n",
    "            s        = 'Number of words', \n",
    "            fontsize = 15\n",
    "           )\n",
    "\n",
    "plt.ylabel (\n",
    "            s        = 'Probability', \n",
    "            fontsize = 15\n",
    "           )\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-14T22:50:58.873581Z",
     "start_time": "2017-08-14T22:50:33.508Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "####################################################\n",
    "\n",
    "def word_match_simple_count ( row ):\n",
    "    \n",
    "    question1_words = {}\n",
    "    question2_words = {}\n",
    "    \n",
    "    for word in str( row['question1'] ).lower().split():\n",
    "        \n",
    "        if word not in stops:\n",
    "            \n",
    "            question1_words[word] = 1\n",
    "            \n",
    "    for word in str( row['question2'] ).lower().split():\n",
    "        \n",
    "        if word not in stops:\n",
    "            \n",
    "            question2_words[word] = 1\n",
    "            \n",
    "    if len(question1_words) == 0 or len(question2_words) == 0:\n",
    "        return 0\n",
    "    \n",
    "    words_shared_question1 = [word for word in question1_words.keys() if word in question2_words]\n",
    "    words_shared_question2 = [word for word in question2_words.keys() if word in question1_words]\n",
    "    \n",
    "    return ( len(words_shared_question1) + len(words_shared_question2) ) / \\\n",
    "           ( len(question1_words)        + len(question2_words)        )\n",
    "\n",
    "####################################################\n",
    "\n",
    "training_data_word_match = training_data.apply (\n",
    "                                                func = word_match_simple_count, \n",
    "                                                axis = 1, \n",
    "                                                raw  = True\n",
    "                                               )\n",
    "\n",
    "plt.hist (\n",
    "          x      = training_data_word_match[training_data['is_duplicate'] == 0], \n",
    "          bins   = 20, \n",
    "          normed = True, \n",
    "          label  = 'Not Duplicate'\n",
    "         )\n",
    "\n",
    "plt.hist ( \n",
    "          x      = training_data_word_match[training_data['is_duplicate'] == 1], \n",
    "          bins   = 20, \n",
    "          normed = True, \n",
    "          alpha  = 0.7, \n",
    "          label  = 'Duplicate'\n",
    "         )\n",
    "\n",
    "plt.title (\n",
    "           s        = 'Label distribution over word_match_share', \n",
    "           fontsize = 15\n",
    "          )\n",
    "\n",
    "plt.xlabel (\n",
    "            s        = 'word_match_share', \n",
    "            fontsize = 15\n",
    "           )\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-14T22:50:58.874885Z",
     "start_time": "2017-08-14T22:50:33.514Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "transformer = TfidfTransformer(smooth_idf=False)\n",
    "\n",
    "transformer \n",
    "\n",
    "#training_questions = pd.Series( training_data['question1'].tolist() + training_data['question2'].tolist() ).astype(str)\n",
    "#testing_questions  = pd.Series( testing_data['question1'].tolist()  + testing_data['question2'].tolist() ).astype(str)\n",
    "\n",
    "counts = [[3, 0, 1],\n",
    "          [2, 0, 0],\n",
    "          [3, 0, 0],\n",
    "          [4, 0, 0],\n",
    "          [3, 2, 0],\n",
    "          [3, 0, 2]]\n",
    "\n",
    "tfidf = transformer.fit_transform(counts)\n",
    "\n",
    "tfidf.toarray() \n",
    "\n",
    "#print tf.get_feature_names()\n",
    "\n",
    "#print len(training_questions)\n",
    "\n",
    "\n",
    "\n",
    "#print tf.get_feature_names()[200:210]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-14T22:50:58.876161Z",
     "start_time": "2017-08-14T22:50:33.517Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Label distribution over word_order_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-14T22:50:58.877691Z",
     "start_time": "2017-08-14T22:50:33.519Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Label distribution over semantic_similarity\n",
    "# http://sujitpal.blogspot.ca/2014/12/semantic-similarity-for-short-sentences.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-14T22:50:58.879789Z",
     "start_time": "2017-08-14T22:50:33.523Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "# tfidf - rare words\n",
    "# from sklearn.feature_extraction.text import TfidfTransformer\n",
    "# https://chisqr.wordpress.com/2017/07/03/classifying-duplicate-questions-with-tensorflow/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-14T22:50:58.881619Z",
     "start_time": "2017-08-14T22:50:33.525Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-14T22:50:58.883298Z",
     "start_time": "2017-08-14T22:50:33.528Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from nltk.corpus import wordnet as wn\n",
    "# nltk.word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-14T22:50:58.884606Z",
     "start_time": "2017-08-14T22:50:33.530Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/abhishekkrthakur/is_that_a_duplicate_quora_question/blob/master/feature_engineering.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## POS Tag, Lemma, Dependency Parsing Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-15T00:41:15.793463Z",
     "start_time": "2017-08-15T00:41:02.384222Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-15T05:42:06.382133Z",
     "start_time": "2017-08-15T05:42:06.314024Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data.head()\n",
    "training_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-15T05:42:21.437006Z",
     "start_time": "2017-08-15T05:42:21.399394Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testing_data.head()\n",
    "testing_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-14T16:47:08.836453Z",
     "start_time": "2017-08-14T16:47:08.829256Z"
    }
   },
   "source": [
    "### 1. Combine training and test data, and remove duplicated questions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-15T00:41:16.272782Z",
     "start_time": "2017-08-15T00:41:15.961957Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all = pd.concat([training_data.question1, training_data.question2, \n",
    "                    testing_data.question1, testing_data.question2], \n",
    "                   axis =0, ignore_index = True) \n",
    "\n",
    "df_all.reset_index(drop=True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-15T00:41:16.387685Z",
     "start_time": "2017-08-15T00:41:16.279179Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-15T00:41:28.485086Z",
     "start_time": "2017-08-15T00:41:16.392088Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-15T00:41:43.604074Z",
     "start_time": "2017-08-15T00:41:28.489498Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_no_dup = df_all.drop_duplicates(keep='first') \n",
    "df_no_dup.reset_index(drop=True, inplace = True)\n",
    "df_no_dup.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extract Name Entity information\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-14T22:39:38.604292Z",
     "start_time": "2017-08-14T22:39:38.567664Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df[361520:361530]\n",
    "\n",
    "# for row in tqdm(range(361557,361530)):\n",
    "#     doc = nlp(unicode(df[row], errors='ignore')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Warning, the following code block takes 3 hours to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-15T03:01:26.447031Z",
     "start_time": "2017-08-15T00:49:16.096509Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "ents_dict = defaultdict(lambda : defaultdict(int))\n",
    "\n",
    "df = df_no_dup\n",
    "iter_len = len(df)\n",
    "for row in tqdm(range(0,iter_len)):\n",
    "    try:\n",
    "        if len(df[row]) > 0:\n",
    "            doc = nlp(df[row]) \n",
    "            for ent in doc.ents:\n",
    "                ents_dict[ent.label_][ent.text] += 1\n",
    "    except TypeError:\n",
    "        print(row, df[row])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-15T06:06:55.876473Z",
     "start_time": "2017-08-15T06:06:54.429394Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ents_dict.keys()\n",
    "ents_set = set()\n",
    "for label in ents_dict.keys():\n",
    "    for text in ents_dict[label].keys():  \n",
    "        if not set('[]~!@#$%^&*()_+{}\":;\\'+-<>?').intersection(text):\n",
    "            ents_set.add(text)\n",
    "            \n",
    "# ents_dict\n",
    "len(ents_set) \n",
    "\n",
    "# remove 'US'\n",
    "ents_set.remove('US')\n",
    "ents_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-15T06:10:35.623312Z",
     "start_time": "2017-08-15T06:10:35.615665Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'india' in ents_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-15T09:05:36.906658Z",
     "start_time": "2017-08-15T09:05:36.894842Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_ent(sent): \n",
    "#     print(sent)\n",
    "    sent_new = sent\n",
    "    for ent in ents_set:\n",
    "#         print('\\\\b'+re.escape(ent)+'\\\\b')\n",
    "#        print(ent)\n",
    "        sent_new = re.sub('\\\\b'+ent+'\\\\b', ent, sent_new, flags=re.IGNORECASE|re.MULTILINE|re.X)\n",
    "    return sent_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-15T09:06:51.215625Z",
     "start_time": "2017-08-15T09:05:38.938113Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = training_data.copy()[:2]\n",
    "\n",
    "# Register `pandas.progress_apply` and `pandas.Series.map_apply` with `tqdm`\n",
    "# (can use `tqdm_gui`, `tqdm_notebook`, optional kwargs, etc.)\n",
    "# tqdm.pandas(desc=\"my bar!\")\n",
    "\n",
    "# Now you can use `progress_apply` instead of `apply`\n",
    "# and `progress_map` instead of `map`\n",
    "# df.progress_apply(lambda x: x**2)\n",
    "\n",
    "df['sent1'] = df.question1.progress_apply(preprocess_ent)\n",
    "# df['sent2'] = df.question2.apply(preprocess_ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-15T06:07:22.019399Z",
     "start_time": "2017-08-15T06:07:21.983981Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-14T22:45:15.766153Z",
     "start_time": "2017-08-14T22:45:15.687218Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, row in df.iterrows():\n",
    "    print row[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-15T06:09:41.146747Z",
     "start_time": "2017-08-15T06:09:41.138436Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent = df.question1[0]\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-15T06:10:02.415229Z",
     "start_time": "2017-08-15T06:10:02.406246Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "re.sub('\\\\b'+'India'+'\\\\b', 'India', sent, flags=re.IGNORECASE|re.MULTILINE|re.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
