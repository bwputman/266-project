{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import math\n",
    "import nltk\n",
    "import scipy  # https://docs.scipy.org/doc/scipy/reference/spatial.distance.html\n",
    "              # https://machinelearning1.wordpress.com/2013/04/10/calculating-spatial-distance-metric-in-python/\n",
    "import gensim\n",
    "import decimal\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "####################################################\n",
    "\n",
    "# convert sentences to vectors\n",
    "\n",
    "def sent2vec( sentence ):\n",
    "    \n",
    "    words             = str( sentence ).lower().decode('utf-8')\n",
    "    words             = nltk.word_tokenize( words )\n",
    "    words             = [word for word in words if not word in stopwords]\n",
    "    words             = [word for word in words if word.isalpha()]\n",
    "    \n",
    "    word_vector_list  = []\n",
    "\n",
    "    for word in words:\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            word_vector_list.append( word2vec[word] )\n",
    "            \n",
    "        except:\n",
    "            \n",
    "            continue\n",
    "    \n",
    "    \n",
    "    word_vector_array = np.array( word_vector_list )\n",
    "    \n",
    "    if len(word_vector_list) == 0:\n",
    "        sentence_vector = np.zeros(300)\n",
    "    else:\n",
    "        sentence_vector = word_vector_array.sum( axis=0 )\n",
    "    \n",
    "    return sentence_vector\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "def braycurtis_distance ( row ):\n",
    "\n",
    "    question1_vector = question1_vector_lookup[row['question1']]\n",
    "    question2_vector = question2_vector_lookup[row['question2']]\n",
    "    \n",
    "    return scipy.spatial.distance.braycurtis (\n",
    "                                              np.nan_to_num( question1_vector ), \n",
    "                                              np.nan_to_num( question2_vector )\n",
    "                                             )\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "def canberra_distance ( row ):\n",
    "\n",
    "    question1_vector = question1_vector_lookup[row['question1']]\n",
    "    question2_vector = question2_vector_lookup[row['question2']]\n",
    "    \n",
    "    return scipy.spatial.distance.canberra (\n",
    "                                            np.nan_to_num( question1_vector ), \n",
    "                                            np.nan_to_num( question2_vector )\n",
    "                                           )\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "def chebyshev_distance ( row ):\n",
    "\n",
    "    question1_vector = question1_vector_lookup[row['question1']]\n",
    "    question2_vector = question2_vector_lookup[row['question2']]\n",
    "    \n",
    "    return scipy.spatial.distance.chebyshev (\n",
    "                                             np.nan_to_num( question1_vector ), \n",
    "                                             np.nan_to_num( question2_vector )\n",
    "                                            )\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "def cityblock_distance ( row ):\n",
    "\n",
    "    question1_vector = question1_vector_lookup[row['question1']]\n",
    "    question2_vector = question2_vector_lookup[row['question2']]\n",
    "    \n",
    "    return scipy.spatial.distance.cityblock (\n",
    "                                             np.nan_to_num( question1_vector ), \n",
    "                                             np.nan_to_num( question2_vector )\n",
    "                                            )\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "def correlation_distance ( row ):\n",
    "\n",
    "    question1_vector = question1_vector_lookup[row['question1']]\n",
    "    question2_vector = question2_vector_lookup[row['question2']]\n",
    "    \n",
    "    return scipy.spatial.distance.correlation (\n",
    "                                               np.nan_to_num( question1_vector ), \n",
    "                                               np.nan_to_num( question2_vector )\n",
    "                                              )\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "def cosine_distance ( row ):\n",
    "\n",
    "    question1_vector = question1_vector_lookup[row['question1']]\n",
    "    question2_vector = question2_vector_lookup[row['question2']]\n",
    "    \n",
    "    return scipy.spatial.distance.cosine (\n",
    "                                          np.nan_to_num( question1_vector ), \n",
    "                                          np.nan_to_num( question2_vector )\n",
    "                                         )\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "def euclidean_distance ( row ):\n",
    "\n",
    "    question1_vector = question1_vector_lookup[row['question1']]\n",
    "    question2_vector = question2_vector_lookup[row['question2']]\n",
    "    \n",
    "    return scipy.spatial.distance.euclidean (\n",
    "                                             np.nan_to_num( question1_vector ), \n",
    "                                             np.nan_to_num( question2_vector )\n",
    "                                            )\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "def hamming_distance ( row ):\n",
    "\n",
    "    question1_vector = question1_vector_lookup[row['question1']]\n",
    "    question2_vector = question2_vector_lookup[row['question2']]\n",
    "    \n",
    "    return scipy.spatial.distance.hamming (\n",
    "                                           np.nan_to_num( question1_vector ), \n",
    "                                           np.nan_to_num( question2_vector )\n",
    "                                          )\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "def jaccard_distance ( row ):\n",
    "\n",
    "    question1_vector = question1_vector_lookup[row['question1']]\n",
    "    question2_vector = question2_vector_lookup[row['question2']]\n",
    "    \n",
    "    return scipy.spatial.distance.jaccard (\n",
    "                                           np.nan_to_num( question1_vector ), \n",
    "                                           np.nan_to_num( question2_vector )\n",
    "                                          )\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "def matching_distance ( row ):\n",
    "\n",
    "    question1_vector = question1_vector_lookup[row['question1']]\n",
    "    question2_vector = question2_vector_lookup[row['question2']]\n",
    "    \n",
    "    return scipy.spatial.distance.matching (\n",
    "                                            np.nan_to_num( question1_vector ), \n",
    "                                            np.nan_to_num( question2_vector )\n",
    "                                           )\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "def minkowski_distance ( row ):\n",
    "\n",
    "    question1_vector = question1_vector_lookup[row['question1']]\n",
    "    question2_vector = question2_vector_lookup[row['question2']]\n",
    "    \n",
    "    return scipy.spatial.distance.minkowski (\n",
    "                                             np.nan_to_num( question1_vector ), \n",
    "                                             np.nan_to_num( question2_vector ),\n",
    "                                             3\n",
    "                                            )\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "def russellrao_distance ( row ):\n",
    "\n",
    "    question1_vector = question1_vector_lookup[row['question1']]\n",
    "    question2_vector = question2_vector_lookup[row['question2']]\n",
    "    \n",
    "    return scipy.spatial.distance.russellrao (\n",
    "                                              np.nan_to_num( question1_vector ), \n",
    "                                              np.nan_to_num( question2_vector )\n",
    "                                             )\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "def sqeuclidean_distance ( row ):\n",
    "\n",
    "    question1_vector = question1_vector_lookup[row['question1']]\n",
    "    question2_vector = question2_vector_lookup[row['question2']]\n",
    "    \n",
    "    return scipy.spatial.distance.sqeuclidean (\n",
    "                                               np.nan_to_num( question1_vector ), \n",
    "                                               np.nan_to_num( question2_vector )\n",
    "                                              )\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "####################################################\n",
    "\n",
    "def wordmovers_distance ( row ):\n",
    "\n",
    "    question1 = str(row['question1']).lower().split()\n",
    "    question2 = str(row['question2']).lower().split()\n",
    "    \n",
    "    question1 = [word for word in question1 if word not in stopwords]\n",
    "    question2 = [word for word in question2 if word not in stopwords]\n",
    "\n",
    "    return word2vec.wmdistance(question1, question2)\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "####################################################\n",
    "\n",
    "def wordmovers_normalized_distance ( row ):\n",
    "\n",
    "    question1 = str(row['question1']).lower().split()\n",
    "    question2 = str(row['question2']).lower().split()\n",
    "    \n",
    "    question1 = [word for word in question1 if word not in stopwords]\n",
    "    question2 = [word for word in question2 if word not in stopwords]\n",
    "\n",
    "    return word2vec_normalized.wmdistance(question1, question2)\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "def question1_skew ( row ):\n",
    "\n",
    "    question1_vector = question1_vector_lookup[row['question1']]\n",
    "    \n",
    "    return scipy.stats.skew(np.nan_to_num( question1_vector ))\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "def question2_skew ( row ):\n",
    "\n",
    "    question2_vector = question2_vector_lookup[row['question2']]\n",
    "    \n",
    "    return scipy.stats.skew(np.nan_to_num( question2_vector ))\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "def question1_kurtosis ( row ):\n",
    "\n",
    "    question1_vector = question1_vector_lookup[row['question1']]\n",
    "    \n",
    "    return scipy.stats.kurtosis(np.nan_to_num( question1_vector ))\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "def question2_kurtosis ( row ):\n",
    "\n",
    "    question2_vector = question2_vector_lookup[row['question2']]\n",
    "    \n",
    "    return scipy.stats.kurtosis(np.nan_to_num( question2_vector ))\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "####################################################\n",
    "\n",
    "def fuzzy_qratio ( row ):\n",
    "    return fuzz.QRatio(str(row['question1']), str(row['question2']))\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "####################################################\n",
    "\n",
    "def fuzzy_WRatio ( row ):\n",
    "    return fuzz.WRatio(str(row['question1']), str(row['question2']))\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "####################################################\n",
    "\n",
    "def fuzzy_partial_ratio ( row ):\n",
    "    return fuzz.partial_ratio(str(row['question1']), str(row['question2']))\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "####################################################\n",
    "\n",
    "def fuzzy_partial_token_set_ratio ( row ):\n",
    "    return fuzz.partial_token_set_ratio(str(row['question1']), str(row['question2']))\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "####################################################\n",
    "\n",
    "def fuzzy_partial_token_sort_ratio ( row ):\n",
    "    return fuzz.partial_token_sort_ratio(str(row['question1']), str(row['question2']))\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "####################################################\n",
    "\n",
    "def fuzzy_token_set_ratio ( row ):\n",
    "    return fuzz.token_set_ratio(str(row['question1']), str(row['question2']))\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "####################################################\n",
    "\n",
    "def fuzzy_token_sort_ratio ( row ):\n",
    "    return fuzz.token_sort_ratio(str(row['question1']), str(row['question2']))\n",
    "\n",
    "####################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stops = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "####################################################\n",
    "\n",
    "# determine the number of matching words between question1 and question2 using a simple count and normalize\n",
    "\n",
    "def word_match_simple_count ( row ):\n",
    "    \n",
    "    question1_words = {}\n",
    "    question2_words = {}\n",
    "    \n",
    "    for word in str( row['question1'] ).lower().split():\n",
    "        \n",
    "        if word not in stops:\n",
    "            \n",
    "            question1_words[word] = 1\n",
    "            \n",
    "    for word in str( row['question2'] ).lower().split():\n",
    "        \n",
    "        if word not in stops:\n",
    "            \n",
    "            question2_words[word] = 1\n",
    "            \n",
    "    if len(question1_words) == 0 or len(question2_words) == 0:\n",
    "        return 0\n",
    "\n",
    "    shared_words_in_question1 = [ word for word in question1_words.keys() if word in question2_words ]\n",
    "    shared_words_in_question2 = [ word for word in question2_words.keys() if word in question1_words ]\n",
    "    \n",
    "    return ( len(shared_words_in_question1) + len(shared_words_in_question2) ) / \\\n",
    "           ( len(question1_words)           + len(question2_words)           )\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "# calculate a weight for each word\n",
    "\n",
    "# If a word frequency is below the minimum count, we ignore the word\n",
    "# smoothing reduces the impact of rare words\n",
    "\n",
    "def get_word_weight ( count, smoothing, minimum_count ):\n",
    "\n",
    "    if count < minimum_count:\n",
    "\n",
    "        return 0\n",
    "    \n",
    "    else:\n",
    "\n",
    "        return 1 / (count + smoothing)\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stops = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "\n",
    "####################################################\n",
    "\n",
    "# determine the number of matching words between question1 and question2 using a per word weight and normalize\n",
    "\n",
    "def word_match_simple_weight ( row ):\n",
    "    \n",
    "    question1_words = {}\n",
    "    question2_words = {}\n",
    "    \n",
    "    for word in str( row['question1'] ).lower().split():\n",
    "        \n",
    "        if word not in stops:\n",
    "            \n",
    "            question1_words[word] = 1\n",
    "            \n",
    "    for word in str( row['question2'] ).lower().split():\n",
    "        \n",
    "        if word not in stops:\n",
    "            \n",
    "            question2_words[word] = 1\n",
    "            \n",
    "    if len(question1_words) == 0 or len(question2_words) == 0:\n",
    "        return 0\n",
    "    \n",
    "    shared_weights = [ word_weights.get(word, 0) for word in question1_words.keys() if word in question2_words ] + \\\n",
    "                     [ word_weights.get(word, 0) for word in question2_words.keys() if word in question1_words ]\n",
    "        \n",
    "    total_weights  = [ word_weights.get(word, 0) for word in question1_words ] + \\\n",
    "                     [ word_weights.get(word, 0) for word in question2_words ]\n",
    "    \n",
    "    return np.sum( shared_weights ) / np.sum( total_weights )\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load training and testing dataset\n",
      "Calculate a weight for each word from the training and testing datasets\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "\n",
    "print 'Load training and testing dataset'\n",
    "\n",
    "training_data       = pd.read_csv(                                     '/home/ubuntu/mini_train.csv' )\n",
    "testing_data        = pd.read_csv(                                     '/home/ubuntu/mini_test.csv' )\n",
    "\n",
    "word2vec            = gensim.models.KeyedVectors.load_word2vec_format (\n",
    "                                                                    '/home/ubuntu/GoogleNews-vectors-negative300.bin', \n",
    "                                                                    binary = True\n",
    "                                                                      )\n",
    "\n",
    "word2vec_normalized = gensim.models.KeyedVectors.load_word2vec_format (\n",
    "                                                                    '/home/ubuntu/GoogleNews-vectors-negative300.bin', \n",
    "                                                                    binary = True\n",
    "                                                                      )\n",
    "word2vec_normalized.init_sims(replace=True)\n",
    "\n",
    "training_questions  = pd.Series ( \n",
    "                                 training_data['question1'].tolist() +\n",
    "                                 training_data['question2'].tolist() \n",
    "                                ).astype(str)\n",
    "\n",
    "testing_questions   = pd.Series ( \n",
    "                                 testing_data['question1'].tolist() +\n",
    "                                 testing_data['question2'].tolist() \n",
    "                                ).astype(str)\n",
    "\n",
    "question1_vector_lookup = {}\n",
    "question2_vector_lookup = {}\n",
    "\n",
    "count = 0\n",
    "for index, row in training_data.iterrows():\n",
    "    question1_vector_lookup[row['question1']] = sent2vec(row['question1'])\n",
    "    question2_vector_lookup[row['question2']] = sent2vec(row['question2'])\n",
    "    count += 1\n",
    "    if count % 100000 == 0:\n",
    "        print 'training: ' + str(count)\n",
    "\n",
    "count = 0\n",
    "for index, row in testing_data.iterrows():\n",
    "    question1_vector_lookup[row['question1']] = sent2vec(row['question1'])\n",
    "    question2_vector_lookup[row['question2']] = sent2vec(row['question2'])\n",
    "    count += 1\n",
    "    if count % 100000 == 0:\n",
    "        print 'testing: ' + str(count)\n",
    "\n",
    "####################################################\n",
    "\n",
    "print 'Calculate a weight for each word from the training and testing datasets'\n",
    "\n",
    "word_count         = collections.defaultdict(int)\n",
    "\n",
    "for question in training_questions:\n",
    "    for word in question.lower().split():\n",
    "        word_count[word] += 1\n",
    "\n",
    "for question in testing_questions:\n",
    "    for word in question.lower().split():\n",
    "        word_count[word] += 1\n",
    "\n",
    "word_weights        = {word : get_word_weight ( \n",
    "                                               count, \n",
    "                                               smoothing     = 10000, \n",
    "                                               minimum_count = 2\n",
    "                                              ) for word, count in word_count.items()}\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare training and testing data\n",
      "train - word_match_simple_count\n",
      "train - word_match_simple_weight\n",
      "train - braycurtis_distance\n",
      "train - canberra_distance\n",
      "train - chebyshev_distance\n",
      "train - cityblock_distance\n",
      "train - correlation_distance\n",
      "train - cosine_distance\n",
      "train - euclidean_distance\n",
      "train - hamming_distance\n",
      "train - jaccard_distance\n",
      "train - matching_distance\n",
      "train - minkowski_distance\n",
      "train - russellrao_distance\n",
      "train - sqeuclidean_distance\n",
      "train - wordmovers_distance\n",
      "train - wordmovers_normalized_distance\n",
      "train - basic features\n",
      "train - skew_question1_vector\n",
      "train - skew_question2_vector\n",
      "train - kurtosis_question1_vector\n",
      "train - kurtosis_question2_vector\n",
      "train - fuzzy_qratio\n",
      "train - fuzzy_WRatio\n",
      "train - fuzzy_partial_ratio\n",
      "train - fuzzy_partial_token_set_ratio\n",
      "train - fuzzy_partial_token_sort_ratio\n",
      "train - fuzzy_token_set_ratio\n",
      "train - fuzzy_token_sort_ratio\n",
      "test - word_match_simple_count\n",
      "test - word_match_simple_weight\n",
      "test - braycurtis_distance\n",
      "test - canberra_distance\n",
      "test - chebyshev_distance\n",
      "test - cityblock_distance\n",
      "test - correlation_distance\n",
      "test - cosine_distance\n",
      "test - euclidean_distance\n",
      "test - hamming_distance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/scipy/spatial/distance.py:543: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - np.dot(um, vm) / (norm(um) * norm(vm))\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/spatial/distance.py:505: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - np.dot(u, v) / (norm(u) * norm(v))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test - jaccard_distance\n",
      "test - matching_distance\n",
      "test - minkowski_distance\n",
      "test - russellrao_distance\n",
      "test - sqeuclidean_distance\n",
      "test - wordmovers_distance\n",
      "test - wordmovers_normalized_distance\n",
      "test - basic features\n",
      "test - skew_question1_vector\n",
      "test - skew_question2_vector\n",
      "test - kurtosis_question1_vector\n",
      "test - kurtosis_question2_vector\n",
      "test - fuzzy_qratio\n",
      "test - fuzzy_WRatio\n",
      "test - fuzzy_partial_ratio\n",
      "test - fuzzy_partial_token_set_ratio\n",
      "test - fuzzy_partial_token_sort_ratio\n",
      "test - fuzzy_token_set_ratio\n",
      "test - fuzzy_token_sort_ratio\n",
      "Split the data for training\n",
      "Convert data to XGB format\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "####################################################\n",
    "\n",
    "print 'Prepare training and testing data'\n",
    "\n",
    "x_train                             = pd.DataFrame()\n",
    "x_test                              = pd.DataFrame()\n",
    "\n",
    "####################################################\n",
    "\n",
    "x_train['word_match_simple_count']  = training_data.apply (\n",
    "                                                           func = word_match_simple_count, \n",
    "                                                           axis = 1, \n",
    "                                                           raw  = True\n",
    "                                                          )\n",
    "print 'train - word_match_simple_count'\n",
    "\n",
    "x_train['word_match_simple_weight'] = training_data.apply (\n",
    "                                                           func = word_match_simple_weight, \n",
    "                                                           axis = 1, \n",
    "                                                           raw  = True\n",
    "                                                          )\n",
    "print 'train - word_match_simple_weight'\n",
    "\n",
    "x_train['braycurtis_distance']      = training_data.apply (\n",
    "                                                           func = braycurtis_distance, \n",
    "                                                           axis = 1, \n",
    "                                                           raw  = True\n",
    "                                                          )\n",
    "print 'train - braycurtis_distance'\n",
    "\n",
    "x_train['canberra_distance']        = training_data.apply (\n",
    "                                                           func = canberra_distance, \n",
    "                                                           axis = 1, \n",
    "                                                           raw  = True\n",
    "                                                          )\n",
    "print 'train - canberra_distance'\n",
    "\n",
    "x_train['chebyshev_distance']       = training_data.apply (\n",
    "                                                           func = chebyshev_distance, \n",
    "                                                           axis = 1, \n",
    "                                                           raw  = True\n",
    "                                                          )\n",
    "print 'train - chebyshev_distance'\n",
    "\n",
    "x_train['cityblock_distance']       = training_data.apply (\n",
    "                                                           func = cityblock_distance, \n",
    "                                                           axis = 1, \n",
    "                                                           raw  = True\n",
    "                                                          )\n",
    "print 'train - cityblock_distance'\n",
    "\n",
    "x_train['correlation_distance']     = training_data.apply (\n",
    "                                                           func = correlation_distance, \n",
    "                                                           axis = 1, \n",
    "                                                           raw  = True\n",
    "                                                          )\n",
    "print 'train - correlation_distance'\n",
    "\n",
    "x_train['cosine_distance']          = training_data.apply (\n",
    "                                                           func = cosine_distance, \n",
    "                                                           axis = 1, \n",
    "                                                           raw  = True\n",
    "                                                          )\n",
    "print 'train - cosine_distance'\n",
    "\n",
    "x_train['euclidean_distance']       = training_data.apply (\n",
    "                                                           func = euclidean_distance, \n",
    "                                                           axis = 1, \n",
    "                                                           raw  = True\n",
    "                                                          )\n",
    "print 'train - euclidean_distance'\n",
    "\n",
    "x_train['hamming_distance']         = training_data.apply (\n",
    "                                                           func = hamming_distance, \n",
    "                                                           axis = 1, \n",
    "                                                           raw  = True\n",
    "                                                          )\n",
    "print 'train - hamming_distance'\n",
    "\n",
    "x_train['jaccard_distance']         = training_data.apply (\n",
    "                                                           func = jaccard_distance, \n",
    "                                                           axis = 1, \n",
    "                                                           raw  = True\n",
    "                                                          )\n",
    "print 'train - jaccard_distance'\n",
    "\n",
    "x_train['matching_distance']        = training_data.apply (\n",
    "                                                           func = matching_distance, \n",
    "                                                           axis = 1, \n",
    "                                                           raw  = True\n",
    "                                                          )\n",
    "print 'train - matching_distance'\n",
    "\n",
    "x_train['minkowski_distance']       = training_data.apply (\n",
    "                                                           func = minkowski_distance, \n",
    "                                                           axis = 1, \n",
    "                                                           raw  = True\n",
    "                                                          )\n",
    "print 'train - minkowski_distance'\n",
    "\n",
    "x_train['russellrao_distance']      = training_data.apply (\n",
    "                                                           func = russellrao_distance, \n",
    "                                                           axis = 1, \n",
    "                                                           raw  = True\n",
    "                                                          )\n",
    "print 'train - russellrao_distance'\n",
    "\n",
    "x_train['sqeuclidean_distance']     = training_data.apply (\n",
    "                                                           func = sqeuclidean_distance, \n",
    "                                                           axis = 1, \n",
    "                                                           raw  = True\n",
    "                                                          )\n",
    "print 'train - sqeuclidean_distance'\n",
    "\n",
    "x_train['wordmovers_distance']     = training_data.apply (\n",
    "                                                           func = wordmovers_distance, \n",
    "                                                           axis = 1, \n",
    "                                                           raw  = True\n",
    "                                                          )\n",
    "print 'train - wordmovers_distance'\n",
    "\n",
    "x_train['wordmovers_normalized_distance'] = training_data.apply (\n",
    "                                                           func = wordmovers_normalized_distance, \n",
    "                                                           axis = 1, \n",
    "                                                           raw  = True\n",
    "                                                          )\n",
    "print 'train - wordmovers_normalized_distance'\n",
    "\n",
    "x_train['length_question1']               = training_data.question1.apply(lambda x: len(str(x)))\n",
    "x_train['length_question2']               = training_data.question2.apply(lambda x: len(str(x)))\n",
    "x_train['length_difference']              = x_train['length_question1'] - x_train['length_question2']\n",
    "x_train['number_characters_question1']    = training_data.question1.apply(lambda x: len(''.join(set(str(x).replace(' ', '')))))\n",
    "x_train['number_characters_question2']    = training_data.question2.apply(lambda x: len(''.join(set(str(x).replace(' ', '')))))\n",
    "x_train['number_words_question1']         = training_data.question1.apply(lambda x: len(str(x).split()))\n",
    "x_train['number_words_question2']         = training_data.question2.apply(lambda x: len(str(x).split()))\n",
    "x_train['common_words']                   = training_data.apply(lambda x: len(set(str(x['question1']).lower().split()).intersection(set(str(x['question2']).lower().split()))), axis=1)\n",
    "print 'train - basic features'\n",
    "\n",
    "x_train['skew_question1_vector']          = training_data.apply (\n",
    "                                                                 func = question1_skew,\n",
    "                                                                 axis = 1, \n",
    "                                                                 raw  = True\n",
    "                                                                )\n",
    "print 'train - skew_question1_vector'\n",
    "\n",
    "x_train['skew_question2_vector']          = training_data.apply (\n",
    "                                                                 func = question2_skew,\n",
    "                                                                 axis = 1, \n",
    "                                                                 raw  = True\n",
    "                                                                )\n",
    "print 'train - skew_question2_vector'\n",
    "\n",
    "x_train['kurtosis_question1_vector']      = training_data.apply (\n",
    "                                                                 func = question1_kurtosis,\n",
    "                                                                 axis = 1, \n",
    "                                                                 raw  = True\n",
    "                                                                )\n",
    "print 'train - kurtosis_question1_vector'\n",
    "\n",
    "x_train['kurtosis_question2_vector']      = training_data.apply (\n",
    "                                                                 func = question2_kurtosis,\n",
    "                                                                 axis = 1, \n",
    "                                                                 raw  = True\n",
    "                                                                )\n",
    "print 'train - kurtosis_question2_vector'\n",
    "\n",
    "x_train['fuzzy_qratio']                   = training_data.apply (\n",
    "                                                                 func = fuzzy_qratio,\n",
    "                                                                 axis = 1, \n",
    "                                                                 raw  = True\n",
    "                                                                )\n",
    "print 'train - fuzzy_qratio'\n",
    "\n",
    "x_train['fuzzy_WRatio']                   = training_data.apply (\n",
    "                                                                 func = fuzzy_WRatio,\n",
    "                                                                 axis = 1, \n",
    "                                                                 raw  = True\n",
    "                                                                )\n",
    "print 'train - fuzzy_WRatio'\n",
    "\n",
    "x_train['fuzzy_partial_ratio']            = training_data.apply (\n",
    "                                                                 func = fuzzy_partial_ratio,\n",
    "                                                                 axis = 1, \n",
    "                                                                 raw  = True\n",
    "                                                                )\n",
    "print 'train - fuzzy_partial_ratio'\n",
    "\n",
    "x_train['fuzzy_partial_token_set_ratio']  = training_data.apply (\n",
    "                                                                 func = fuzzy_partial_token_set_ratio,\n",
    "                                                                 axis = 1, \n",
    "                                                                 raw  = True\n",
    "                                                                )\n",
    "print 'train - fuzzy_partial_token_set_ratio'\n",
    "\n",
    "x_train['fuzzy_partial_token_sort_ratio'] = training_data.apply (\n",
    "                                                                 func = fuzzy_partial_token_sort_ratio,\n",
    "                                                                 axis = 1, \n",
    "                                                                 raw  = True\n",
    "                                                                )\n",
    "print 'train - fuzzy_partial_token_sort_ratio'\n",
    "\n",
    "x_train['fuzzy_token_set_ratio']          = training_data.apply (\n",
    "                                                                 func = fuzzy_token_set_ratio,\n",
    "                                                                 axis = 1, \n",
    "                                                                 raw  = True\n",
    "                                                                )\n",
    "print 'train - fuzzy_token_set_ratio'\n",
    "\n",
    "x_train['fuzzy_token_sort_ratio']         = training_data.apply (\n",
    "                                                                 func = fuzzy_token_sort_ratio,\n",
    "                                                                 axis = 1, \n",
    "                                                                 raw  = True\n",
    "                                                                )\n",
    "print 'train - fuzzy_token_sort_ratio'\n",
    "\n",
    "####################################################\n",
    "\n",
    "x_test['word_match_simple_count']  = testing_data.apply (\n",
    "                                                         func = word_match_simple_count, \n",
    "                                                         axis = 1, \n",
    "                                                         raw  = True\n",
    "                                                        )\n",
    "print 'test - word_match_simple_count'\n",
    "\n",
    "x_test['word_match_simple_weight'] = testing_data.apply (\n",
    "                                                         func = word_match_simple_weight, \n",
    "                                                         axis = 1, \n",
    "                                                         raw  = True\n",
    "                                                        )\n",
    "print 'test - word_match_simple_weight'\n",
    "\n",
    "x_test['braycurtis_distance']      = testing_data.apply (\n",
    "                                                         func = braycurtis_distance, \n",
    "                                                         axis = 1, \n",
    "                                                         raw  = True\n",
    "                                                        )\n",
    "print 'test - braycurtis_distance'\n",
    "\n",
    "x_test['canberra_distance']        = testing_data.apply (\n",
    "                                                         func = canberra_distance, \n",
    "                                                         axis = 1, \n",
    "                                                         raw  = True\n",
    "                                                        )\n",
    "print 'test - canberra_distance'\n",
    "\n",
    "x_test['chebyshev_distance']       = testing_data.apply (\n",
    "                                                         func = chebyshev_distance, \n",
    "                                                         axis = 1, \n",
    "                                                         raw  = True\n",
    "                                                        )\n",
    "print 'test - chebyshev_distance'\n",
    "\n",
    "x_test['cityblock_distance']       = testing_data.apply (\n",
    "                                                         func = cityblock_distance, \n",
    "                                                         axis = 1, \n",
    "                                                         raw  = True\n",
    "                                                        )\n",
    "print 'test - cityblock_distance'\n",
    "\n",
    "x_test['correlation_distance']     = testing_data.apply (\n",
    "                                                         func = correlation_distance, \n",
    "                                                         axis = 1, \n",
    "                                                         raw  = True\n",
    "                                                        )\n",
    "print 'test - correlation_distance'\n",
    "\n",
    "x_test['cosine_distance']          = testing_data.apply (\n",
    "                                                         func = cosine_distance, \n",
    "                                                         axis = 1, \n",
    "                                                         raw  = True\n",
    "                                                        )\n",
    "print 'test - cosine_distance'\n",
    "\n",
    "x_test['euclidean_distance']       = testing_data.apply (\n",
    "                                                         func = euclidean_distance, \n",
    "                                                         axis = 1, \n",
    "                                                         raw  = True\n",
    "                                                        )\n",
    "print 'test - euclidean_distance'\n",
    "\n",
    "x_test['hamming_distance']         = testing_data.apply (\n",
    "                                                         func = hamming_distance, \n",
    "                                                         axis = 1, \n",
    "                                                         raw  = True\n",
    "                                                        )\n",
    "print 'test - hamming_distance'\n",
    "\n",
    "x_test['jaccard_distance']         = testing_data.apply (\n",
    "                                                         func = jaccard_distance, \n",
    "                                                         axis = 1, \n",
    "                                                         raw  = True\n",
    "                                                        )\n",
    "print 'test - jaccard_distance'\n",
    "\n",
    "x_test['matching_distance']        = testing_data.apply (\n",
    "                                                         func = matching_distance, \n",
    "                                                         axis = 1, \n",
    "                                                         raw  = True\n",
    "                                                        )\n",
    "print 'test - matching_distance'\n",
    "\n",
    "x_test['minkowski_distance']       = testing_data.apply (\n",
    "                                                         func = minkowski_distance, \n",
    "                                                         axis = 1, \n",
    "                                                         raw  = True\n",
    "                                                        )\n",
    "print 'test - minkowski_distance'\n",
    "\n",
    "x_test['russellrao_distance']      = testing_data.apply (\n",
    "                                                         func = russellrao_distance, \n",
    "                                                         axis = 1, \n",
    "                                                         raw  = True\n",
    "                                                        )\n",
    "print 'test - russellrao_distance'\n",
    "\n",
    "x_test['sqeuclidean_distance']     = testing_data.apply (\n",
    "                                                         func = sqeuclidean_distance, \n",
    "                                                         axis = 1, \n",
    "                                                         raw  = True\n",
    "                                                        )\n",
    "print 'test - sqeuclidean_distance'\n",
    "\n",
    "x_test['wordmovers_distance']      = testing_data.apply (\n",
    "                                                         func = wordmovers_distance, \n",
    "                                                         axis = 1, \n",
    "                                                         raw  = True\n",
    "                                                        )\n",
    "print 'test - wordmovers_distance'\n",
    "\n",
    "x_test['wordmovers_normalized_distance'] = testing_data.apply (\n",
    "                                                         func = wordmovers_normalized_distance, \n",
    "                                                         axis = 1, \n",
    "                                                         raw  = True\n",
    "                                                        )\n",
    "print 'test - wordmovers_normalized_distance'\n",
    "\n",
    "x_test['length_question1']               = testing_data.question1.apply(lambda x: len(str(x)))\n",
    "x_test['length_question2']               = testing_data.question2.apply(lambda x: len(str(x)))\n",
    "x_test['length_difference']              = x_test['length_question1'] - x_train['length_question2']\n",
    "x_test['number_characters_question1']    = testing_data.question1.apply(lambda x: len(''.join(set(str(x).replace(' ', '')))))\n",
    "x_test['number_characters_question2']    = testing_data.question2.apply(lambda x: len(''.join(set(str(x).replace(' ', '')))))\n",
    "x_test['number_words_question1']         = testing_data.question1.apply(lambda x: len(str(x).split()))\n",
    "x_test['number_words_question2']         = testing_data.question2.apply(lambda x: len(str(x).split()))\n",
    "x_test['common_words']                   = testing_data.apply(lambda x: len(set(str(x['question1']).lower().split()).intersection(set(str(x['question2']).lower().split()))), axis=1)\n",
    "print 'test - basic features'\n",
    "\n",
    "x_test['skew_question1_vector']          = testing_data.apply (\n",
    "                                                               func = question1_skew,\n",
    "                                                               axis = 1, \n",
    "                                                               raw  = True\n",
    "                                                              )\n",
    "print 'test - skew_question1_vector'\n",
    "\n",
    "x_test['skew_question2_vector']          = testing_data.apply (\n",
    "                                                               func = question2_skew,\n",
    "                                                               axis = 1, \n",
    "                                                               raw  = True\n",
    "                                                              )\n",
    "print 'test - skew_question2_vector'\n",
    "\n",
    "x_test['kurtosis_question1_vector']      = testing_data.apply (\n",
    "                                                               func = question1_kurtosis,\n",
    "                                                               axis = 1, \n",
    "                                                               raw  = True\n",
    "                                                              )\n",
    "print 'test - kurtosis_question1_vector'\n",
    "\n",
    "x_test['kurtosis_question2_vector']      = testing_data.apply (\n",
    "                                                               func = question2_kurtosis,\n",
    "                                                               axis = 1, \n",
    "                                                               raw  = True\n",
    "                                                              )\n",
    "\n",
    "print 'test - kurtosis_question2_vector'\n",
    "\n",
    "x_test['fuzzy_qratio']                   = testing_data.apply (\n",
    "                                                               func = fuzzy_qratio,\n",
    "                                                               axis = 1, \n",
    "                                                               raw  = True\n",
    "                                                              )\n",
    "print 'test - fuzzy_qratio'\n",
    "\n",
    "x_test['fuzzy_WRatio']                   = testing_data.apply (\n",
    "                                                               func = fuzzy_WRatio,\n",
    "                                                               axis = 1, \n",
    "                                                               raw  = True\n",
    "                                                              )\n",
    "print 'test - fuzzy_WRatio'\n",
    "\n",
    "x_test['fuzzy_partial_ratio']            = testing_data.apply (\n",
    "                                                               func = fuzzy_partial_ratio,\n",
    "                                                               axis = 1, \n",
    "                                                               raw  = True\n",
    "                                                              )\n",
    "print 'test - fuzzy_partial_ratio'\n",
    "\n",
    "x_test['fuzzy_partial_token_set_ratio']  = testing_data.apply (\n",
    "                                                               func = fuzzy_partial_token_set_ratio,\n",
    "                                                               axis = 1, \n",
    "                                                               raw  = True\n",
    "                                                              )\n",
    "print 'test - fuzzy_partial_token_set_ratio'\n",
    "\n",
    "x_test['fuzzy_partial_token_sort_ratio'] = testing_data.apply (\n",
    "                                                               func = fuzzy_partial_token_sort_ratio,\n",
    "                                                               axis = 1, \n",
    "                                                               raw  = True\n",
    "                                                              )\n",
    "print 'test - fuzzy_partial_token_sort_ratio'\n",
    "\n",
    "x_test['fuzzy_token_set_ratio']          = testing_data.apply (\n",
    "                                                               func = fuzzy_token_set_ratio,\n",
    "                                                               axis = 1, \n",
    "                                                               raw  = True\n",
    "                                                              )\n",
    "print 'test - fuzzy_token_set_ratio'\n",
    "\n",
    "x_test['fuzzy_token_sort_ratio']         = testing_data.apply (\n",
    "                                                               func = fuzzy_token_sort_ratio,\n",
    "                                                               axis = 1, \n",
    "                                                               raw  = True\n",
    "                                                              )\n",
    "print 'test - fuzzy_token_sort_ratio'\n",
    "\n",
    "####################################################\n",
    "\n",
    "y_train                             = training_data['is_duplicate'].values\n",
    "\n",
    "####################################################\n",
    "\n",
    "print 'Split the data for training'\n",
    "\n",
    "x_train, x_valid, y_train, y_valid  = train_test_split (\n",
    "                                                        x_train,\n",
    "                                                        y_train, \n",
    "                                                        test_size    = 0.2, \n",
    "                                                        random_state = 4242\n",
    "                                                       )\n",
    "\n",
    "####################################################\n",
    "\n",
    "print 'Convert data to XGB format'\n",
    "\n",
    "data_train                          = xgb.DMatrix (\n",
    "                                                   data  = x_train,  \n",
    "                                                   label = y_train\n",
    "                                                  )\n",
    "\n",
    "data_validate                       = xgb.DMatrix (\n",
    "                                                   data  = x_valid, \n",
    "                                                   label = y_valid\n",
    "                                                  )\n",
    "\n",
    "####################################################\n",
    "\n",
    "data_test                           = xgb.DMatrix (\n",
    "                                                   data  = x_test\n",
    "                                                  )\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   word_match_simple_count  word_match_simple_weight  braycurtis_distance  \\\n",
      "0                 0.266667                  0.500031             0.490320   \n",
      "1                 0.500000                  0.600026             0.250493   \n",
      "2                 0.444444                  0.571713             0.346363   \n",
      "3                 0.000000                  0.000000             0.503057   \n",
      "4                 0.800000                  1.000000             0.000000   \n",
      "\n",
      "   canberra_distance  chebyshev_distance  cityblock_distance  \\\n",
      "0         165.240416            1.488525          114.431046   \n",
      "1         116.091678            0.649414           53.327644   \n",
      "2         132.997571            0.693359           62.257957   \n",
      "3         171.692092            0.619873           54.527912   \n",
      "4           0.000000            0.000000            0.000000   \n",
      "\n",
      "   correlation_distance  cosine_distance  euclidean_distance  \\\n",
      "0          3.972893e-01     3.954516e-01            8.468845   \n",
      "1          1.090954e-01     1.089034e-01            3.817149   \n",
      "2          1.637411e-01     1.636005e-01            4.425264   \n",
      "3          3.245042e-01     3.196543e-01            3.878658   \n",
      "4          4.734304e-08     9.255779e-08            0.000000   \n",
      "\n",
      "   hamming_distance           ...            skew_question2_vector  \\\n",
      "0               1.0           ...                         0.009958   \n",
      "1               1.0           ...                        -0.046821   \n",
      "2               1.0           ...                        -0.058206   \n",
      "3               1.0           ...                         0.069599   \n",
      "4               0.0           ...                         0.006085   \n",
      "\n",
      "   kurtosis_question1_vector  kurtosis_question2_vector  fuzzy_qratio  \\\n",
      "0                   0.039938                  -0.144867            46   \n",
      "1                   0.207580                  -0.042937            49   \n",
      "2                  -0.505311                  -0.379896            60   \n",
      "3                  -0.241065                   0.774025            52   \n",
      "4                  -0.081314                  -0.081314            70   \n",
      "\n",
      "   fuzzy_WRatio  fuzzy_partial_ratio  fuzzy_partial_token_set_ratio  \\\n",
      "0            55                   46                            100   \n",
      "1            86                   56                            100   \n",
      "2            86                   76                            100   \n",
      "3            54                   53                             63   \n",
      "4            70                   63                            100   \n",
      "\n",
      "   fuzzy_partial_token_sort_ratio  fuzzy_token_set_ratio  \\\n",
      "0                              59                     58   \n",
      "1                              64                     82   \n",
      "2                              68                     92   \n",
      "3                              63                     52   \n",
      "4                              66                     74   \n",
      "\n",
      "   fuzzy_token_sort_ratio  \n",
      "0                      55  \n",
      "1                      58  \n",
      "2                      55  \n",
      "3                      52  \n",
      "4                      66  \n",
      "\n",
      "[5 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "print x_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execute the XGBoost model\n",
      "[0]\ttrain-logloss:0.68077\tvalid-logloss:0.687372\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "[10]\ttrain-logloss:0.576782\tvalid-logloss:0.645439\n",
      "[20]\ttrain-logloss:0.495736\tvalid-logloss:0.627704\n",
      "[30]\ttrain-logloss:0.434344\tvalid-logloss:0.62306\n",
      "[40]\ttrain-logloss:0.386656\tvalid-logloss:0.618616\n",
      "[50]\ttrain-logloss:0.346757\tvalid-logloss:0.617644\n",
      "[60]\ttrain-logloss:0.31217\tvalid-logloss:0.621845\n",
      "[70]\ttrain-logloss:0.284605\tvalid-logloss:0.619451\n",
      "[80]\ttrain-logloss:0.259496\tvalid-logloss:0.621326\n",
      "[90]\ttrain-logloss:0.237657\tvalid-logloss:0.626243\n",
      "Stopping. Best iteration:\n",
      "[48]\ttrain-logloss:0.354595\tvalid-logloss:0.615391\n",
      "\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "\n",
    "print 'Execute the XGBoost model'\n",
    "\n",
    "XGB_parameters                                 = {}\n",
    "XGB_parameters['objective']                    = 'binary:logistic'\n",
    "XGB_parameters['eval_metric']                  = 'logloss'\n",
    "XGB_parameters['eta']                          = 0.02\n",
    "XGB_parameters['max_depth']                    = 4\n",
    "\n",
    "XGB_watchlist                                  = [\n",
    "                                                  (data_train,      'train'), \n",
    "                                                  (data_validate,   'valid')\n",
    "                                                 ]\n",
    "\n",
    "XGB_booster = xgb.train (\n",
    "                         params                = XGB_parameters, \n",
    "                         dtrain                = data_train, \n",
    "                         num_boost_round       = 1000, \n",
    "                         evals                 = XGB_watchlist, \n",
    "                         early_stopping_rounds = 50, \n",
    "                         verbose_eval          = 10\n",
    "                        )\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make predictions and create submission file\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "\n",
    "print 'Make predictions and create submission file'\n",
    "\n",
    "predictions                    = XGB_booster.predict( data_test )\n",
    "\n",
    "submission                     = pd.DataFrame()\n",
    "\n",
    "submission['test_id']          = testing_data['test_id']\n",
    "submission['is_duplicate']     = predictions\n",
    "\n",
    "submission.to_csv (\n",
    "                   path_or_buf = 'XGBOOST_submission_to_kaggle.csv', \n",
    "                   index       = False\n",
    "                  )\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
