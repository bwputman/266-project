{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T13:10:20.467573Z",
     "start_time": "2017-08-20T13:10:14.968816Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/anaconda3/envs/python2.7/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import math\n",
    "import nltk\n",
    "import scipy  # https://docs.scipy.org/doc/scipy/reference/spatial.distance.html\n",
    "              # https://machinelearning1.wordpress.com/2013/04/10/calculating-spatial-distance-metric-in-python/\n",
    "import gensim\n",
    "import decimal\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T13:10:20.655571Z",
     "start_time": "2017-08-20T13:10:20.473267Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df_train = pd.read_pickle(\"./data/df_train_s.pkl\")\n",
    "df_test = pd.read_pickle(\"./data/df_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T13:10:20.665882Z",
     "start_time": "2017-08-20T13:10:20.658578Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_ = df_train[['id', 'sbj_share', 'verb_share','obj_share', 'svo_cnt1', 'svo_cnt2', 'doc_sim' ]]\n",
    "# df_.to_pickle(\"./data/df_train_s.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T13:10:20.841207Z",
     "start_time": "2017-08-20T13:10:20.672097Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sbj_share</th>\n",
       "      <th>verb_share</th>\n",
       "      <th>obj_share</th>\n",
       "      <th>svo_cnt1</th>\n",
       "      <th>svo_cnt2</th>\n",
       "      <th>doc_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>248200</th>\n",
       "      <td>248200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.911897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353591</th>\n",
       "      <td>353591</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229626</th>\n",
       "      <td>229626</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.897367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170156</th>\n",
       "      <td>170156</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.955990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169884</th>\n",
       "      <td>169884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.988462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318784</th>\n",
       "      <td>318784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.709531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242464</th>\n",
       "      <td>242464</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.979788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21391</th>\n",
       "      <td>21391</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.951001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352365</th>\n",
       "      <td>352365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.935561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307519</th>\n",
       "      <td>307519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.936812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  sbj_share  verb_share  obj_share  svo_cnt1  svo_cnt2   doc_sim\n",
       "248200  248200        0.0         0.0        0.0         0         0  0.911897\n",
       "353591  353591        0.0         0.0        0.0         0         0  0.997023\n",
       "229626  229626        0.0         0.0        0.0         0         0  0.897367\n",
       "170156  170156        1.0         1.0        1.0         2         2  0.955990\n",
       "169884  169884        0.0         0.0        0.0         1         0  0.988462\n",
       "318784  318784        0.0         0.0        0.0         0         0  0.709531\n",
       "242464  242464        1.0         1.0        1.0         1         1  0.979788\n",
       "21391    21391        1.0         0.0        1.0         1         1  0.951001\n",
       "352365  352365        0.0         0.0        1.0         1         1  0.935561\n",
       "307519  307519        0.0         0.0        0.0         1         0  0.936812"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T13:10:20.879010Z",
     "start_time": "2017-08-20T13:10:20.849759Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svo_share(row, train_data = True ):\n",
    "    if train_data:\n",
    "#         row_index = row.id\n",
    "        row_index = df_train[df_train.id == row.id].index[0]\n",
    "    \n",
    "        svo_cnt1 = df_train['svo_cnt1'][row_index]\n",
    "        svo_cnt2 = df_train['svo_cnt2'][row_index]\n",
    "        sbj_share = df_train['sbj_share'][row_index]\n",
    "        verb_share = df_train['verb_share'][row_index]\n",
    "        obj_share = df_train['obj_share'][row_index]\n",
    "    else:\n",
    "#         row_index = row.test_id \n",
    "        row_index = df_test[df_test.test_id == row.test_id].index[0]\n",
    "        \n",
    "        svo_cnt1 = df_test['svo_cnt1'][row_index]\n",
    "        svo_cnt2 = df_test['svo_cnt2'][row_index]\n",
    "        sbj_share = df_test['obj_share'][row_index]\n",
    "        verb_share = df_test['verb_share'][row_index]\n",
    "        obj_share = df_test['obj_share'][row_index]\n",
    "    return svo_cnt1, svo_cnt2, sbj_share, verb_share, obj_share\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T13:10:21.021861Z",
     "start_time": "2017-08-20T13:10:20.888084Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_ = training_data\n",
    "\n",
    "# df_['svo_cnt1'], df_['svo_cnt2'], \\\n",
    "# df_['sbj_share'], df_['verb_share'], df_['obj_share']\\\n",
    "# = zip( *df_.apply(lambda row: svo_share(row , train_data = True), axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T13:10:21.089238Z",
     "start_time": "2017-08-20T13:10:21.025650Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_t = testing_data\n",
    "\n",
    "# df_t['svo_cnt1'], df_t['svo_cnt2'], \\\n",
    "# df_t['sbj_share'], df_t['verb_share'], df_t['obj_share']\\\n",
    "# = zip( *df_t.apply(lambda row: svo_share(row , train_data = False), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T13:10:21.155973Z",
     "start_time": "2017-08-20T13:10:21.092996Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T13:10:21.325412Z",
     "start_time": "2017-08-20T13:10:21.160635Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T13:10:21.413496Z",
     "start_time": "2017-08-20T13:10:21.334937Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "####################################################\n",
    "\n",
    "# convert sentences to vectors\n",
    "\n",
    "def sent2vec( sentence ):\n",
    "    \n",
    "    words             = str( sentence ).lower().decode('utf-8')\n",
    "    words             = nltk.word_tokenize( words )\n",
    "    words             = [word for word in words if not word in stopwords]\n",
    "    words             = [word for word in words if word.isalpha()]\n",
    "    \n",
    "    word_vector_list  = []\n",
    "\n",
    "    for word in words:\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            word_vector_list.append( word2vec[word] )\n",
    "            \n",
    "        except:\n",
    "            \n",
    "            continue\n",
    "    \n",
    "    \n",
    "    word_vector_array = np.array( word_vector_list )\n",
    "    \n",
    "    if len(word_vector_list) == 0:\n",
    "        sentence_vector = np.zeros(300)\n",
    "    else:\n",
    "        sentence_vector = word_vector_array.sum( axis=0 )\n",
    "    \n",
    "    return sentence_vector\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T13:10:21.505382Z",
     "start_time": "2017-08-20T13:10:21.418425Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "def braycurtis_distance ( row ):\n",
    "\n",
    "    question1_vector = question1_vector_lookup[row['question1']]\n",
    "    question2_vector = question2_vector_lookup[row['question2']]\n",
    "    \n",
    "    return scipy.spatial.distance.braycurtis (\n",
    "                                              np.nan_to_num( question1_vector ), \n",
    "                                              np.nan_to_num( question2_vector )\n",
    "                                             )\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T13:10:21.601067Z",
     "start_time": "2017-08-20T13:10:21.510142Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "def canberra_distance ( row ):\n",
    "\n",
    "    question1_vector = question1_vector_lookup[row['question1']]\n",
    "    question2_vector = question2_vector_lookup[row['question2']]\n",
    "    \n",
    "    return scipy.spatial.distance.canberra (\n",
    "                                            np.nan_to_num( question1_vector ), \n",
    "                                            np.nan_to_num( question2_vector )\n",
    "                                           )\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T13:10:21.667503Z",
     "start_time": "2017-08-20T13:10:21.605157Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "def chebyshev_distance ( row ):\n",
    "\n",
    "    question1_vector = question1_vector_lookup[row['question1']]\n",
    "    question2_vector = question2_vector_lookup[row['question2']]\n",
    "    \n",
    "    return scipy.spatial.distance.chebyshev (\n",
    "                                             np.nan_to_num( question1_vector ), \n",
    "                                             np.nan_to_num( question2_vector )\n",
    "                                            )\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T13:10:21.759206Z",
     "start_time": "2017-08-20T13:10:21.671503Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "def cityblock_distance ( row ):\n",
    "\n",
    "    question1_vector = question1_vector_lookup[row['question1']]\n",
    "    question2_vector = question2_vector_lookup[row['question2']]\n",
    "    \n",
    "    return scipy.spatial.distance.cityblock (\n",
    "                                             np.nan_to_num( question1_vector ), \n",
    "                                             np.nan_to_num( question2_vector )\n",
    "                                            )\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T13:10:21.837876Z",
     "start_time": "2017-08-20T13:10:21.763387Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "def correlation_distance ( row ):\n",
    "\n",
    "    question1_vector = question1_vector_lookup[row['question1']]\n",
    "    question2_vector = question2_vector_lookup[row['question2']]\n",
    "    \n",
    "    return scipy.spatial.distance.correlation (\n",
    "                                               np.nan_to_num( question1_vector ), \n",
    "                                               np.nan_to_num( question2_vector )\n",
    "                                              )\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T13:10:21.932529Z",
     "start_time": "2017-08-20T13:10:21.841842Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "def cosine_distance ( row ):\n",
    "\n",
    "    question1_vector = question1_vector_lookup[row['question1']]\n",
    "    question2_vector = question2_vector_lookup[row['question2']]\n",
    "    \n",
    "    return scipy.spatial.distance.cosine (\n",
    "                                          np.nan_to_num( question1_vector ), \n",
    "                                          np.nan_to_num( question2_vector )\n",
    "                                         )\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T13:10:22.015520Z",
     "start_time": "2017-08-20T13:10:21.936340Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "def euclidean_distance ( row ):\n",
    "\n",
    "    question1_vector = question1_vector_lookup[row['question1']]\n",
    "    question2_vector = question2_vector_lookup[row['question2']]\n",
    "    \n",
    "    return scipy.spatial.distance.euclidean (\n",
    "                                             np.nan_to_num( question1_vector ), \n",
    "                                             np.nan_to_num( question2_vector )\n",
    "                                            )\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T13:10:22.087531Z",
     "start_time": "2017-08-20T13:10:22.019349Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "def hamming_distance ( row ):\n",
    "\n",
    "    question1_vector = question1_vector_lookup[row['question1']]\n",
    "    question2_vector = question2_vector_lookup[row['question2']]\n",
    "    \n",
    "    return scipy.spatial.distance.hamming (\n",
    "                                           np.nan_to_num( question1_vector ), \n",
    "                                           np.nan_to_num( question2_vector )\n",
    "                                          )\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T13:10:22.162162Z",
     "start_time": "2017-08-20T13:10:22.091441Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "def jaccard_distance ( row ):\n",
    "\n",
    "    question1_vector = question1_vector_lookup[row['question1']]\n",
    "    question2_vector = question2_vector_lookup[row['question2']]\n",
    "    \n",
    "    return scipy.spatial.distance.jaccard (\n",
    "                                           np.nan_to_num( question1_vector ), \n",
    "                                           np.nan_to_num( question2_vector )\n",
    "                                          )\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T13:10:22.235430Z",
     "start_time": "2017-08-20T13:10:22.166882Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "def matching_distance ( row ):\n",
    "\n",
    "    question1_vector = question1_vector_lookup[row['question1']]\n",
    "    question2_vector = question2_vector_lookup[row['question2']]\n",
    "    \n",
    "    return scipy.spatial.distance.matching (\n",
    "                                            np.nan_to_num( question1_vector ), \n",
    "                                            np.nan_to_num( question2_vector )\n",
    "                                           )\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T13:10:22.302861Z",
     "start_time": "2017-08-20T13:10:22.239955Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "def minkowski_distance ( row ):\n",
    "\n",
    "    question1_vector = question1_vector_lookup[row['question1']]\n",
    "    question2_vector = question2_vector_lookup[row['question2']]\n",
    "    \n",
    "    return scipy.spatial.distance.minkowski (\n",
    "                                             np.nan_to_num( question1_vector ), \n",
    "                                             np.nan_to_num( question2_vector ),\n",
    "                                             3\n",
    "                                            )\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T13:10:22.376225Z",
     "start_time": "2017-08-20T13:10:22.306658Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "def russellrao_distance ( row ):\n",
    "\n",
    "    question1_vector = question1_vector_lookup[row['question1']]\n",
    "    question2_vector = question2_vector_lookup[row['question2']]\n",
    "    \n",
    "    return scipy.spatial.distance.russellrao (\n",
    "                                              np.nan_to_num( question1_vector ), \n",
    "                                              np.nan_to_num( question2_vector )\n",
    "                                             )\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T13:10:22.461713Z",
     "start_time": "2017-08-20T13:10:22.380336Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "def sqeuclidean_distance ( row ):\n",
    "\n",
    "    question1_vector = question1_vector_lookup[row['question1']]\n",
    "    question2_vector = question2_vector_lookup[row['question2']]\n",
    "    \n",
    "    return scipy.spatial.distance.sqeuclidean (\n",
    "                                               np.nan_to_num( question1_vector ), \n",
    "                                               np.nan_to_num( question2_vector )\n",
    "                                              )\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T13:10:22.527093Z",
     "start_time": "2017-08-20T13:10:22.465726Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "####################################################\n",
    "\n",
    "def wordmovers_distance ( row ):\n",
    "\n",
    "    question1 = str(row['question1']).lower().split()\n",
    "    question2 = str(row['question2']).lower().split()\n",
    "    \n",
    "    question1 = [word for word in question1 if word not in stopwords]\n",
    "    question2 = [word for word in question2 if word not in stopwords]\n",
    "\n",
    "    return word2vec.wmdistance(question1, question2)\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T13:10:22.595570Z",
     "start_time": "2017-08-20T13:10:22.531006Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "####################################################\n",
    "\n",
    "def wordmovers_normalized_distance ( row ):\n",
    "\n",
    "    question1 = str(row['question1']).lower().split()\n",
    "    question2 = str(row['question2']).lower().split()\n",
    "    \n",
    "    question1 = [word for word in question1 if word not in stopwords]\n",
    "    question2 = [word for word in question2 if word not in stopwords]\n",
    "\n",
    "    return word2vec_normalized.wmdistance(question1, question2)\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T13:10:22.693288Z",
     "start_time": "2017-08-20T13:10:22.599468Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "def question1_skew ( row ):\n",
    "\n",
    "    question1_vector = question1_vector_lookup[row['question1']]\n",
    "    \n",
    "    return scipy.stats.skew(np.nan_to_num( question1_vector ))\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T13:10:22.761967Z",
     "start_time": "2017-08-20T13:10:22.697271Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "def question2_skew ( row ):\n",
    "\n",
    "    question2_vector = question2_vector_lookup[row['question2']]\n",
    "    \n",
    "    return scipy.stats.skew(np.nan_to_num( question2_vector ))\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T13:10:22.825992Z",
     "start_time": "2017-08-20T13:10:22.766810Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "def question1_kurtosis ( row ):\n",
    "\n",
    "    question1_vector = question1_vector_lookup[row['question1']]\n",
    "    \n",
    "    return scipy.stats.kurtosis(np.nan_to_num( question1_vector ))\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T13:10:22.900906Z",
     "start_time": "2017-08-20T13:10:22.830163Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "def question2_kurtosis ( row ):\n",
    "\n",
    "    question2_vector = question2_vector_lookup[row['question2']]\n",
    "    \n",
    "    return scipy.stats.kurtosis(np.nan_to_num( question2_vector ))\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T13:10:22.971175Z",
     "start_time": "2017-08-20T13:10:22.904924Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "####################################################\n",
    "\n",
    "def fuzzy_qratio ( row ):\n",
    "    return fuzz.QRatio(str(row['question1']), str(row['question2']))\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T13:10:23.042472Z",
     "start_time": "2017-08-20T13:10:22.976142Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "####################################################\n",
    "\n",
    "def fuzzy_WRatio ( row ):\n",
    "    return fuzz.WRatio(str(row['question1']), str(row['question2']))\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T13:10:23.138615Z",
     "start_time": "2017-08-20T13:10:23.046851Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "####################################################\n",
    "\n",
    "def fuzzy_partial_ratio ( row ):\n",
    "    return fuzz.partial_ratio(str(row['question1']), str(row['question2']))\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T13:10:23.200931Z",
     "start_time": "2017-08-20T13:10:23.142472Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "####################################################\n",
    "\n",
    "def fuzzy_partial_token_set_ratio ( row ):\n",
    "    return fuzz.partial_token_set_ratio(str(row['question1']), str(row['question2']))\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T13:10:23.278471Z",
     "start_time": "2017-08-20T13:10:23.204835Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "####################################################\n",
    "\n",
    "def fuzzy_partial_token_sort_ratio ( row ):\n",
    "    return fuzz.partial_token_sort_ratio(str(row['question1']), str(row['question2']))\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T13:10:23.342665Z",
     "start_time": "2017-08-20T13:10:23.286856Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "####################################################\n",
    "\n",
    "def fuzzy_token_set_ratio ( row ):\n",
    "    return fuzz.token_set_ratio(str(row['question1']), str(row['question2']))\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T13:10:23.412120Z",
     "start_time": "2017-08-20T13:10:23.346528Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "####################################################\n",
    "\n",
    "def fuzzy_token_sort_ratio ( row ):\n",
    "    return fuzz.token_sort_ratio(str(row['question1']), str(row['question2']))\n",
    "\n",
    "####################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T13:10:23.570538Z",
     "start_time": "2017-08-20T13:10:23.416825Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stops = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "####################################################\n",
    "\n",
    "# determine the number of matching words between question1 and question2 using a simple count and normalize\n",
    "\n",
    "def word_match_simple_count ( row ):\n",
    "    \n",
    "    question1_words = {}\n",
    "    question2_words = {}\n",
    "    \n",
    "    for word in str( row['question1'] ).lower().split():\n",
    "        \n",
    "        if word not in stops:\n",
    "            \n",
    "            question1_words[word] = 1\n",
    "            \n",
    "    for word in str( row['question2'] ).lower().split():\n",
    "        \n",
    "        if word not in stops:\n",
    "            \n",
    "            question2_words[word] = 1\n",
    "            \n",
    "    if len(question1_words) == 0 or len(question2_words) == 0:\n",
    "        return 0\n",
    "\n",
    "    shared_words_in_question1 = [ word for word in question1_words.keys() if word in question2_words ]\n",
    "    shared_words_in_question2 = [ word for word in question2_words.keys() if word in question1_words ]\n",
    "    \n",
    "    return ( len(shared_words_in_question1) + len(shared_words_in_question2) ) / \\\n",
    "           ( len(question1_words)           + len(question2_words)           )\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T13:10:23.858636Z",
     "start_time": "2017-08-20T13:10:23.583923Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "# calculate a weight for each word\n",
    "\n",
    "# If a word frequency is below the minimum count, we ignore the word\n",
    "# smoothing reduces the impact of rare words\n",
    "\n",
    "def get_word_weight ( count, smoothing, minimum_count ):\n",
    "\n",
    "    if count < minimum_count:\n",
    "\n",
    "        return 0\n",
    "    \n",
    "    else:\n",
    "\n",
    "        return 1 / (count + smoothing)\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T13:10:23.952765Z",
     "start_time": "2017-08-20T13:10:23.865639Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stops = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "\n",
    "####################################################\n",
    "\n",
    "# determine the number of matching words between question1 and question2 using a per word weight and normalize\n",
    "\n",
    "def word_match_simple_weight ( row ):\n",
    "    \n",
    "    question1_words = {}\n",
    "    question2_words = {}\n",
    "    \n",
    "    for word in str( row['question1'] ).lower().split():\n",
    "        \n",
    "        if word not in stops:\n",
    "            \n",
    "            question1_words[word] = 1\n",
    "            \n",
    "    for word in str( row['question2'] ).lower().split():\n",
    "        \n",
    "        if word not in stops:\n",
    "            \n",
    "            question2_words[word] = 1\n",
    "            \n",
    "    if len(question1_words) == 0 or len(question2_words) == 0:\n",
    "        return 0\n",
    "    \n",
    "    shared_weights = [ word_weights.get(word, 0) for word in question1_words.keys() if word in question2_words ] + \\\n",
    "                     [ word_weights.get(word, 0) for word in question2_words.keys() if word in question1_words ]\n",
    "        \n",
    "    total_weights  = [ word_weights.get(word, 0) for word in question1_words ] + \\\n",
    "                     [ word_weights.get(word, 0) for word in question2_words ]\n",
    "    \n",
    "    return np.sum( shared_weights ) / np.sum( total_weights )\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T13:10:24.061106Z",
     "start_time": "2017-08-20T13:10:23.964622Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load training and testing dataset\n"
     ]
    }
   ],
   "source": [
    "print 'Load training and testing dataset'\n",
    "\n",
    "training_data       = pd.read_csv('./mini_train.csv' )\n",
    "testing_data        = pd.read_csv('./mini_test.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T12:48:07.319386Z",
     "start_time": "2017-08-20T12:45:02.204339Z"
    }
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "\n",
    "\n",
    "word2vec            = gensim.models.KeyedVectors.load_word2vec_format (\n",
    "                                                            './wordvec/GoogleNews-vectors-negative300.bin', \n",
    "                                                                    binary = True\n",
    "                                                                      )\n",
    "\n",
    "word2vec_normalized = gensim.models.KeyedVectors.load_word2vec_format (\n",
    "                                                            './wordvec//GoogleNews-vectors-negative300.bin', \n",
    "                                                                    binary = True\n",
    "                                                                      )\n",
    "word2vec_normalized.init_sims(replace=True)\n",
    "\n",
    "training_questions  = pd.Series ( \n",
    "                                 training_data['question1'].tolist() +\n",
    "                                 training_data['question2'].tolist() \n",
    "                                ).astype(str)\n",
    "\n",
    "testing_questions   = pd.Series ( \n",
    "                                 testing_data['question1'].tolist() +\n",
    "                                 testing_data['question2'].tolist() \n",
    "                                ).astype(str)\n",
    "\n",
    "question1_vector_lookup = {}\n",
    "question2_vector_lookup = {}\n",
    "\n",
    "count = 0\n",
    "for index, row in training_data.iterrows():\n",
    "    question1_vector_lookup[row['question1']] = sent2vec(row['question1'])\n",
    "    question2_vector_lookup[row['question2']] = sent2vec(row['question2'])\n",
    "    count += 1\n",
    "    if count % 100000 == 0:\n",
    "        print 'training: ' + str(count)\n",
    "\n",
    "count = 0\n",
    "for index, row in testing_data.iterrows():\n",
    "    question1_vector_lookup[row['question1']] = sent2vec(row['question1'])\n",
    "    question2_vector_lookup[row['question2']] = sent2vec(row['question2'])\n",
    "    count += 1\n",
    "    if count % 100000 == 0:\n",
    "        print 'testing: ' + str(count)\n",
    "\n",
    "####################################################\n",
    "\n",
    "print 'Calculate a weight for each word from the training and testing datasets'\n",
    "\n",
    "word_count         = collections.defaultdict(int)\n",
    "\n",
    "for question in training_questions:\n",
    "    for word in question.lower().split():\n",
    "        word_count[word] += 1\n",
    "\n",
    "for question in testing_questions:\n",
    "    for word in question.lower().split():\n",
    "        word_count[word] += 1\n",
    "\n",
    "word_weights        = {word : get_word_weight ( \n",
    "                                               count, \n",
    "                                               smoothing     = 10000, \n",
    "                                               minimum_count = 2\n",
    "                                              ) for word, count in word_count.items()}\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T12:48:08.146432Z",
     "start_time": "2017-08-20T12:48:07.322488Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "####################################################\n",
    "\n",
    "print 'Prepare training and testing data'\n",
    "\n",
    "x_train                             = pd.DataFrame()\n",
    "x_test                              = pd.DataFrame()\n",
    "\n",
    "####################################################\n",
    "\n",
    "\n",
    "x_train['svo_cnt1'], x_train['svo_cnt2'], \\\n",
    "x_train['sbj_share'], x_train['verb_share'], x_train['obj_share']\\\n",
    "= zip( *training_data.apply(lambda row: svo_share(row , train_data = True), axis=1))\n",
    "\n",
    "x_test['svo_cnt1'], x_test['svo_cnt2'], \\\n",
    "x_test['sbj_share'], x_test['verb_share'], x_test['obj_share']\\\n",
    "= zip( *testing_data.apply(lambda row: svo_share(row , train_data = False), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "x_train['word_match_simple_count']  = training_data.apply (\n",
    "                                                           func = word_match_simple_count, \n",
    "                                                           axis = 1, \n",
    "                                                           raw  = True\n",
    "                                                          )\n",
    "print 'train - word_match_simple_count'\n",
    "\n",
    "x_train['word_match_simple_weight'] = training_data.apply (\n",
    "                                                           func = word_match_simple_weight, \n",
    "                                                           axis = 1, \n",
    "                                                           raw  = True\n",
    "                                                          )\n",
    "print 'train - word_match_simple_weight'\n",
    "\n",
    "x_train['braycurtis_distance']      = training_data.apply (\n",
    "                                                           func = braycurtis_distance, \n",
    "                                                           axis = 1, \n",
    "                                                           raw  = True\n",
    "                                                          )\n",
    "print 'train - braycurtis_distance'\n",
    "\n",
    "x_train['canberra_distance']        = training_data.apply (\n",
    "                                                           func = canberra_distance, \n",
    "                                                           axis = 1, \n",
    "                                                           raw  = True\n",
    "                                                          )\n",
    "print 'train - canberra_distance'\n",
    "\n",
    "x_train['chebyshev_distance']       = training_data.apply (\n",
    "                                                           func = chebyshev_distance, \n",
    "                                                           axis = 1, \n",
    "                                                           raw  = True\n",
    "                                                          )\n",
    "print 'train - chebyshev_distance'\n",
    "\n",
    "x_train['cityblock_distance']       = training_data.apply (\n",
    "                                                           func = cityblock_distance, \n",
    "                                                           axis = 1, \n",
    "                                                           raw  = True\n",
    "                                                          )\n",
    "print 'train - cityblock_distance'\n",
    "\n",
    "x_train['correlation_distance']     = training_data.apply (\n",
    "                                                           func = correlation_distance, \n",
    "                                                           axis = 1, \n",
    "                                                           raw  = True\n",
    "                                                          )\n",
    "print 'train - correlation_distance'\n",
    "\n",
    "x_train['cosine_distance']          = training_data.apply (\n",
    "                                                           func = cosine_distance, \n",
    "                                                           axis = 1, \n",
    "                                                           raw  = True\n",
    "                                                          )\n",
    "print 'train - cosine_distance'\n",
    "\n",
    "x_train['euclidean_distance']       = training_data.apply (\n",
    "                                                           func = euclidean_distance, \n",
    "                                                           axis = 1, \n",
    "                                                           raw  = True\n",
    "                                                          )\n",
    "print 'train - euclidean_distance'\n",
    "\n",
    "x_train['hamming_distance']         = training_data.apply (\n",
    "                                                           func = hamming_distance, \n",
    "                                                           axis = 1, \n",
    "                                                           raw  = True\n",
    "                                                          )\n",
    "print 'train - hamming_distance'\n",
    "\n",
    "x_train['jaccard_distance']         = training_data.apply (\n",
    "                                                           func = jaccard_distance, \n",
    "                                                           axis = 1, \n",
    "                                                           raw  = True\n",
    "                                                          )\n",
    "print 'train - jaccard_distance'\n",
    "\n",
    "x_train['matching_distance']        = training_data.apply (\n",
    "                                                           func = matching_distance, \n",
    "                                                           axis = 1, \n",
    "                                                           raw  = True\n",
    "                                                          )\n",
    "print 'train - matching_distance'\n",
    "\n",
    "x_train['minkowski_distance']       = training_data.apply (\n",
    "                                                           func = minkowski_distance, \n",
    "                                                           axis = 1, \n",
    "                                                           raw  = True\n",
    "                                                          )\n",
    "print 'train - minkowski_distance'\n",
    "\n",
    "x_train['russellrao_distance']      = training_data.apply (\n",
    "                                                           func = russellrao_distance, \n",
    "                                                           axis = 1, \n",
    "                                                           raw  = True\n",
    "                                                          )\n",
    "print 'train - russellrao_distance'\n",
    "\n",
    "x_train['sqeuclidean_distance']     = training_data.apply (\n",
    "                                                           func = sqeuclidean_distance, \n",
    "                                                           axis = 1, \n",
    "                                                           raw  = True\n",
    "                                                          )\n",
    "print 'train - sqeuclidean_distance'\n",
    "\n",
    "x_train['wordmovers_distance']     = training_data.apply (\n",
    "                                                           func = wordmovers_distance, \n",
    "                                                           axis = 1, \n",
    "                                                           raw  = True\n",
    "                                                          )\n",
    "print 'train - wordmovers_distance'\n",
    "\n",
    "x_train['wordmovers_normalized_distance'] = training_data.apply (\n",
    "                                                           func = wordmovers_normalized_distance, \n",
    "                                                           axis = 1, \n",
    "                                                           raw  = True\n",
    "                                                          )\n",
    "print 'train - wordmovers_normalized_distance'\n",
    "\n",
    "x_train['length_question1']               = training_data.question1.apply(lambda x: len(str(x)))\n",
    "x_train['length_question2']               = training_data.question2.apply(lambda x: len(str(x)))\n",
    "x_train['length_difference']              = x_train['length_question1'] - x_train['length_question2']\n",
    "x_train['number_characters_question1']    = training_data.question1.apply(lambda x: len(''.join(set(str(x).replace(' ', '')))))\n",
    "x_train['number_characters_question2']    = training_data.question2.apply(lambda x: len(''.join(set(str(x).replace(' ', '')))))\n",
    "x_train['number_words_question1']         = training_data.question1.apply(lambda x: len(str(x).split()))\n",
    "x_train['number_words_question2']         = training_data.question2.apply(lambda x: len(str(x).split()))\n",
    "x_train['common_words']                   = training_data.apply(lambda x: len(set(str(x['question1']).lower().split()).intersection(set(str(x['question2']).lower().split()))), axis=1)\n",
    "print 'train - basic features'\n",
    "\n",
    "x_train['skew_question1_vector']          = training_data.apply (\n",
    "                                                                 func = question1_skew,\n",
    "                                                                 axis = 1, \n",
    "                                                                 raw  = True\n",
    "                                                                )\n",
    "print 'train - skew_question1_vector'\n",
    "\n",
    "x_train['skew_question2_vector']          = training_data.apply (\n",
    "                                                                 func = question2_skew,\n",
    "                                                                 axis = 1, \n",
    "                                                                 raw  = True\n",
    "                                                                )\n",
    "print 'train - skew_question2_vector'\n",
    "\n",
    "x_train['kurtosis_question1_vector']      = training_data.apply (\n",
    "                                                                 func = question1_kurtosis,\n",
    "                                                                 axis = 1, \n",
    "                                                                 raw  = True\n",
    "                                                                )\n",
    "print 'train - kurtosis_question1_vector'\n",
    "\n",
    "x_train['kurtosis_question2_vector']      = training_data.apply (\n",
    "                                                                 func = question2_kurtosis,\n",
    "                                                                 axis = 1, \n",
    "                                                                 raw  = True\n",
    "                                                                )\n",
    "print 'train - kurtosis_question2_vector'\n",
    "\n",
    "x_train['fuzzy_qratio']                   = training_data.apply (\n",
    "                                                                 func = fuzzy_qratio,\n",
    "                                                                 axis = 1, \n",
    "                                                                 raw  = True\n",
    "                                                                )\n",
    "print 'train - fuzzy_qratio'\n",
    "\n",
    "x_train['fuzzy_WRatio']                   = training_data.apply (\n",
    "                                                                 func = fuzzy_WRatio,\n",
    "                                                                 axis = 1, \n",
    "                                                                 raw  = True\n",
    "                                                                )\n",
    "print 'train - fuzzy_WRatio'\n",
    "\n",
    "x_train['fuzzy_partial_ratio']            = training_data.apply (\n",
    "                                                                 func = fuzzy_partial_ratio,\n",
    "                                                                 axis = 1, \n",
    "                                                                 raw  = True\n",
    "                                                                )\n",
    "print 'train - fuzzy_partial_ratio'\n",
    "\n",
    "x_train['fuzzy_partial_token_set_ratio']  = training_data.apply (\n",
    "                                                                 func = fuzzy_partial_token_set_ratio,\n",
    "                                                                 axis = 1, \n",
    "                                                                 raw  = True\n",
    "                                                                )\n",
    "print 'train - fuzzy_partial_token_set_ratio'\n",
    "\n",
    "x_train['fuzzy_partial_token_sort_ratio'] = training_data.apply (\n",
    "                                                                 func = fuzzy_partial_token_sort_ratio,\n",
    "                                                                 axis = 1, \n",
    "                                                                 raw  = True\n",
    "                                                                )\n",
    "print 'train - fuzzy_partial_token_sort_ratio'\n",
    "\n",
    "x_train['fuzzy_token_set_ratio']          = training_data.apply (\n",
    "                                                                 func = fuzzy_token_set_ratio,\n",
    "                                                                 axis = 1, \n",
    "                                                                 raw  = True\n",
    "                                                                )\n",
    "print 'train - fuzzy_token_set_ratio'\n",
    "\n",
    "x_train['fuzzy_token_sort_ratio']         = training_data.apply (\n",
    "                                                                 func = fuzzy_token_sort_ratio,\n",
    "                                                                 axis = 1, \n",
    "                                                                 raw  = True\n",
    "                                                                )\n",
    "print 'train - fuzzy_token_sort_ratio'\n",
    "\n",
    "####################################################\n",
    "\n",
    "x_test['word_match_simple_count']  = testing_data.apply (\n",
    "                                                         func = word_match_simple_count, \n",
    "                                                         axis = 1, \n",
    "                                                         raw  = True\n",
    "                                                        )\n",
    "print 'test - word_match_simple_count'\n",
    "\n",
    "x_test['word_match_simple_weight'] = testing_data.apply (\n",
    "                                                         func = word_match_simple_weight, \n",
    "                                                         axis = 1, \n",
    "                                                         raw  = True\n",
    "                                                        )\n",
    "print 'test - word_match_simple_weight'\n",
    "\n",
    "x_test['braycurtis_distance']      = testing_data.apply (\n",
    "                                                         func = braycurtis_distance, \n",
    "                                                         axis = 1, \n",
    "                                                         raw  = True\n",
    "                                                        )\n",
    "print 'test - braycurtis_distance'\n",
    "\n",
    "x_test['canberra_distance']        = testing_data.apply (\n",
    "                                                         func = canberra_distance, \n",
    "                                                         axis = 1, \n",
    "                                                         raw  = True\n",
    "                                                        )\n",
    "print 'test - canberra_distance'\n",
    "\n",
    "x_test['chebyshev_distance']       = testing_data.apply (\n",
    "                                                         func = chebyshev_distance, \n",
    "                                                         axis = 1, \n",
    "                                                         raw  = True\n",
    "                                                        )\n",
    "print 'test - chebyshev_distance'\n",
    "\n",
    "x_test['cityblock_distance']       = testing_data.apply (\n",
    "                                                         func = cityblock_distance, \n",
    "                                                         axis = 1, \n",
    "                                                         raw  = True\n",
    "                                                        )\n",
    "print 'test - cityblock_distance'\n",
    "\n",
    "x_test['correlation_distance']     = testing_data.apply (\n",
    "                                                         func = correlation_distance, \n",
    "                                                         axis = 1, \n",
    "                                                         raw  = True\n",
    "                                                        )\n",
    "print 'test - correlation_distance'\n",
    "\n",
    "x_test['cosine_distance']          = testing_data.apply (\n",
    "                                                         func = cosine_distance, \n",
    "                                                         axis = 1, \n",
    "                                                         raw  = True\n",
    "                                                        )\n",
    "print 'test - cosine_distance'\n",
    "\n",
    "x_test['euclidean_distance']       = testing_data.apply (\n",
    "                                                         func = euclidean_distance, \n",
    "                                                         axis = 1, \n",
    "                                                         raw  = True\n",
    "                                                        )\n",
    "print 'test - euclidean_distance'\n",
    "\n",
    "x_test['hamming_distance']         = testing_data.apply (\n",
    "                                                         func = hamming_distance, \n",
    "                                                         axis = 1, \n",
    "                                                         raw  = True\n",
    "                                                        )\n",
    "print 'test - hamming_distance'\n",
    "\n",
    "x_test['jaccard_distance']         = testing_data.apply (\n",
    "                                                         func = jaccard_distance, \n",
    "                                                         axis = 1, \n",
    "                                                         raw  = True\n",
    "                                                        )\n",
    "print 'test - jaccard_distance'\n",
    "\n",
    "x_test['matching_distance']        = testing_data.apply (\n",
    "                                                         func = matching_distance, \n",
    "                                                         axis = 1, \n",
    "                                                         raw  = True\n",
    "                                                        )\n",
    "print 'test - matching_distance'\n",
    "\n",
    "x_test['minkowski_distance']       = testing_data.apply (\n",
    "                                                         func = minkowski_distance, \n",
    "                                                         axis = 1, \n",
    "                                                         raw  = True\n",
    "                                                        )\n",
    "print 'test - minkowski_distance'\n",
    "\n",
    "x_test['russellrao_distance']      = testing_data.apply (\n",
    "                                                         func = russellrao_distance, \n",
    "                                                         axis = 1, \n",
    "                                                         raw  = True\n",
    "                                                        )\n",
    "print 'test - russellrao_distance'\n",
    "\n",
    "x_test['sqeuclidean_distance']     = testing_data.apply (\n",
    "                                                         func = sqeuclidean_distance, \n",
    "                                                         axis = 1, \n",
    "                                                         raw  = True\n",
    "                                                        )\n",
    "print 'test - sqeuclidean_distance'\n",
    "\n",
    "x_test['wordmovers_distance']      = testing_data.apply (\n",
    "                                                         func = wordmovers_distance, \n",
    "                                                         axis = 1, \n",
    "                                                         raw  = True\n",
    "                                                        )\n",
    "print 'test - wordmovers_distance'\n",
    "\n",
    "x_test['wordmovers_normalized_distance'] = testing_data.apply (\n",
    "                                                         func = wordmovers_normalized_distance, \n",
    "                                                         axis = 1, \n",
    "                                                         raw  = True\n",
    "                                                        )\n",
    "print 'test - wordmovers_normalized_distance'\n",
    "\n",
    "x_test['length_question1']               = testing_data.question1.apply(lambda x: len(str(x)))\n",
    "x_test['length_question2']               = testing_data.question2.apply(lambda x: len(str(x)))\n",
    "x_test['length_difference']              = x_test['length_question1'] - x_train['length_question2']\n",
    "x_test['number_characters_question1']    = testing_data.question1.apply(lambda x: len(''.join(set(str(x).replace(' ', '')))))\n",
    "x_test['number_characters_question2']    = testing_data.question2.apply(lambda x: len(''.join(set(str(x).replace(' ', '')))))\n",
    "x_test['number_words_question1']         = testing_data.question1.apply(lambda x: len(str(x).split()))\n",
    "x_test['number_words_question2']         = testing_data.question2.apply(lambda x: len(str(x).split()))\n",
    "x_test['common_words']                   = testing_data.apply(lambda x: len(set(str(x['question1']).lower().split()).intersection(set(str(x['question2']).lower().split()))), axis=1)\n",
    "print 'test - basic features'\n",
    "\n",
    "x_test['skew_question1_vector']          = testing_data.apply (\n",
    "                                                               func = question1_skew,\n",
    "                                                               axis = 1, \n",
    "                                                               raw  = True\n",
    "                                                              )\n",
    "print 'test - skew_question1_vector'\n",
    "\n",
    "x_test['skew_question2_vector']          = testing_data.apply (\n",
    "                                                               func = question2_skew,\n",
    "                                                               axis = 1, \n",
    "                                                               raw  = True\n",
    "                                                              )\n",
    "print 'test - skew_question2_vector'\n",
    "\n",
    "x_test['kurtosis_question1_vector']      = testing_data.apply (\n",
    "                                                               func = question1_kurtosis,\n",
    "                                                               axis = 1, \n",
    "                                                               raw  = True\n",
    "                                                              )\n",
    "print 'test - kurtosis_question1_vector'\n",
    "\n",
    "x_test['kurtosis_question2_vector']      = testing_data.apply (\n",
    "                                                               func = question2_kurtosis,\n",
    "                                                               axis = 1, \n",
    "                                                               raw  = True\n",
    "                                                              )\n",
    "\n",
    "print 'test - kurtosis_question2_vector'\n",
    "\n",
    "x_test['fuzzy_qratio']                   = testing_data.apply (\n",
    "                                                               func = fuzzy_qratio,\n",
    "                                                               axis = 1, \n",
    "                                                               raw  = True\n",
    "                                                              )\n",
    "print 'test - fuzzy_qratio'\n",
    "\n",
    "x_test['fuzzy_WRatio']                   = testing_data.apply (\n",
    "                                                               func = fuzzy_WRatio,\n",
    "                                                               axis = 1, \n",
    "                                                               raw  = True\n",
    "                                                              )\n",
    "print 'test - fuzzy_WRatio'\n",
    "\n",
    "x_test['fuzzy_partial_ratio']            = testing_data.apply (\n",
    "                                                               func = fuzzy_partial_ratio,\n",
    "                                                               axis = 1, \n",
    "                                                               raw  = True\n",
    "                                                              )\n",
    "print 'test - fuzzy_partial_ratio'\n",
    "\n",
    "x_test['fuzzy_partial_token_set_ratio']  = testing_data.apply (\n",
    "                                                               func = fuzzy_partial_token_set_ratio,\n",
    "                                                               axis = 1, \n",
    "                                                               raw  = True\n",
    "                                                              )\n",
    "print 'test - fuzzy_partial_token_set_ratio'\n",
    "\n",
    "x_test['fuzzy_partial_token_sort_ratio'] = testing_data.apply (\n",
    "                                                               func = fuzzy_partial_token_sort_ratio,\n",
    "                                                               axis = 1, \n",
    "                                                               raw  = True\n",
    "                                                              )\n",
    "print 'test - fuzzy_partial_token_sort_ratio'\n",
    "\n",
    "x_test['fuzzy_token_set_ratio']          = testing_data.apply (\n",
    "                                                               func = fuzzy_token_set_ratio,\n",
    "                                                               axis = 1, \n",
    "                                                               raw  = True\n",
    "                                                              )\n",
    "print 'test - fuzzy_token_set_ratio'\n",
    "\n",
    "x_test['fuzzy_token_sort_ratio']         = testing_data.apply (\n",
    "                                                               func = fuzzy_token_sort_ratio,\n",
    "                                                               axis = 1, \n",
    "                                                               raw  = True\n",
    "                                                              )\n",
    "print 'test - fuzzy_token_sort_ratio'\n",
    "\n",
    "####################################################\n",
    "\n",
    "y_train                             = training_data['is_duplicate'].values\n",
    "\n",
    "####################################################\n",
    "\n",
    "print 'Split the data for training'\n",
    "\n",
    "x_train, x_valid, y_train, y_valid  = train_test_split (\n",
    "                                                        x_train,\n",
    "                                                        y_train, \n",
    "                                                        test_size    = 0.2, \n",
    "                                                        random_state = 4242\n",
    "                                                       )\n",
    "\n",
    "####################################################\n",
    "\n",
    "print 'Convert data to XGB format'\n",
    "\n",
    "data_train                          = xgb.DMatrix (\n",
    "                                                   data  = x_train,  \n",
    "                                                   label = y_train\n",
    "                                                  )\n",
    "\n",
    "data_validate                       = xgb.DMatrix (\n",
    "                                                   data  = x_valid, \n",
    "                                                   label = y_valid\n",
    "                                                  )\n",
    "\n",
    "####################################################\n",
    "\n",
    "data_test                           = xgb.DMatrix (\n",
    "                                                   data  = x_test\n",
    "                                                  )\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print x_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "print 'Execute the XGBoost model'\n",
    "\n",
    "XGB_parameters                                 = {}\n",
    "XGB_parameters['objective']                    = 'binary:logistic'\n",
    "XGB_parameters['eval_metric']                  = 'logloss'\n",
    "XGB_parameters['eta']                          = 0.02\n",
    "XGB_parameters['max_depth']                    = 4\n",
    "\n",
    "XGB_watchlist                                  = [\n",
    "                                                  (data_train,      'train'), \n",
    "                                                  (data_validate,   'valid')\n",
    "                                                 ]\n",
    "\n",
    "XGB_booster = xgb.train (\n",
    "                         params                = XGB_parameters, \n",
    "                         dtrain                = data_train, \n",
    "                         num_boost_round       = 1000, \n",
    "                         evals                 = XGB_watchlist, \n",
    "                         early_stopping_rounds = 50, \n",
    "                         verbose_eval          = 10\n",
    "                        )\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "\n",
    "print 'Make predictions and create submission file'\n",
    "\n",
    "predictions                    = XGB_booster.predict( data_test )\n",
    "\n",
    "submission                     = pd.DataFrame()\n",
    "\n",
    "submission['test_id']          = testing_data['test_id']\n",
    "submission['is_duplicate']     = predictions\n",
    "\n",
    "submission.to_csv (\n",
    "                   path_or_buf = 'XGBOOST_submission_to_kaggle.csv', \n",
    "                   index       = False\n",
    "                  )\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:python2.7]",
   "language": "python",
   "name": "conda-env-python2.7-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
